{"cells":[{"cell_type":"markdown","source":"## LifeLong Machine Learning\n\n### 助教的投影片連結\n[投影片](https://docs.google.com/presentation/d/13JmcOZ9i_m5xJbRBKNMAKE1fIzGhyaeLck3frY0B2xY/edit?usp=sharing)\n\n### 定義\n老師的影片有詳細說明定義 這裡不細提 詳細可以參考 [lifelong learning](https://youtu.be/7qT5P9KJnWo) \n\n\n### 方法\n在2019年底，有人提出了一個大匯整將lifelong learning 的方法，從2016- 2019 年初 的模型做了歸類，大致上可以分成三種大方法\n* Replay-based methods\n* Regularization-based methods\n* Parameter isolation methods\n\n<img src=\"https://i.ibb.co/VDFJkWG/2019-12-29-17-25.png\" width=\"100%\">\n\n在這次的作業之中，我們要走過一次regularization-based methods 裡面的 prior-focused的兩種方法 分別是 EWC 和 MAS 這兩種方法\n\n圖片出處 [Continual Learning in Neural\nNetworks](https://arxiv.org/pdf/1910.02718.pdf)\n\n若有任何問題，歡迎來信至助教信箱 ntu-ml-2020spring-ta@googlegroups.com\n\n\n\n","metadata":{"id":"LD5roJkIvoRj","cell_id":"00000-30beeffd-434a-46ba-97c0-8335d8229c93"}},{"cell_type":"code","metadata":{"id":"ILD0GKIgJPHb","cell_id":"00001-aababcb6-b837-488d-bc05-61087c33b382","output_cleared":false,"source_hash":"31587f3","execution_start":1604580937538,"execution_millis":0},"source":"%%capture\n# !pip3 install torch torchvision","execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Import Libraries","metadata":{"id":"On1VZz4HUIJw","cell_id":"00002-310b6c2b-c018-422c-a9f9-a80f01f61834"}},{"cell_type":"code","source":"!pip install torch==1.7.0","metadata":{"tags":[],"cell_id":"00003-56bd60d6-261b-4d65-ab9a-04396d1507c5","output_cleared":false,"source_hash":"3b55d45b","execution_start":1604580954916,"execution_millis":42203},"outputs":[{"name":"stdout","text":"Collecting torch==1.7.0\n  Downloading torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7 MB)\n\u001b[K     |████████████████████████████████| 776.7 MB 3.1 kB/s \n\u001b[?25hCollecting typing-extensions\n  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\nCollecting dataclasses\n  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\nCollecting future\n  Downloading future-0.18.2.tar.gz (829 kB)\n\u001b[K     |████████████████████████████████| 829 kB 45.5 MB/s \n\u001b[?25hRequirement already satisfied: numpy in /opt/venv/lib/python3.7/site-packages (from torch==1.7.0) (1.19.2)\nBuilding wheels for collected packages: future\n  Building wheel for future (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491059 sha256=c2e468be1a1efbb129af9508e52ac60a039f0592aabb03cd87a13f65d6589444\n  Stored in directory: /home/jovyan/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\nSuccessfully built future\nInstalling collected packages: typing-extensions, dataclasses, future, torch\nSuccessfully installed dataclasses-0.6 future-0.18.2 torch-1.7.0 typing-extensions-3.7.4.3\n\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\nYou should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install torchvision==0.8.1","metadata":{"tags":[],"cell_id":"00004-48dd2b5e-77bf-489a-b7a4-16f96ec5b290","output_cleared":false,"source_hash":"92ae8c5a","execution_start":1604581027922,"execution_millis":2613},"outputs":[{"name":"stdout","text":"Collecting torchvision==0.8.1\n  Downloading torchvision-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (12.7 MB)\n\u001b[K     |████████████████████████████████| 12.7 MB 8.6 MB/s \n\u001b[?25hRequirement already satisfied: numpy in /opt/venv/lib/python3.7/site-packages (from torchvision==0.8.1) (1.19.2)\nRequirement already satisfied: pillow>=4.1.1 in /opt/venv/lib/python3.7/site-packages (from torchvision==0.8.1) (7.2.0)\nRequirement already satisfied: torch==1.7.0 in /opt/venv/lib/python3.7/site-packages (from torchvision==0.8.1) (1.7.0)\nRequirement already satisfied: typing-extensions in /opt/venv/lib/python3.7/site-packages (from torch==1.7.0->torchvision==0.8.1) (3.7.4.3)\nRequirement already satisfied: dataclasses in /opt/venv/lib/python3.7/site-packages (from torch==1.7.0->torchvision==0.8.1) (0.6)\nRequirement already satisfied: future in /opt/venv/lib/python3.7/site-packages (from torch==1.7.0->torchvision==0.8.1) (0.18.2)\nInstalling collected packages: torchvision\nSuccessfully installed torchvision-0.8.1\n\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\nYou should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","metadata":{"id":"dLnpJTNtje_J","cell_id":"00003-5bd7596f-aeab-44fa-8530-e726a2b9d886","output_cleared":false,"source_hash":"a02c94c0","execution_millis":72,"execution_start":1604581034615},"source":"%%capture\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torch.utils.data as data\nimport torch.utils.data.sampler as sampler\nimport torchvision\nfrom torchvision import datasets, transforms\n\nimport numpy as np\nimport os\nimport random\nfrom copy import deepcopy\nimport json\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# 模型","metadata":{"id":"KRGf4QAKFzz9","cell_id":"00004-465f5f91-a016-41c2-8187-c7089b94eda2"}},{"cell_type":"markdown","source":" >因為本次作業強調的是lifelong learning 的訓練方法，並非疊模型，所以今天我們所舉的例子，都會使用同一個模型來做訓練只是應用上不同lifelong learning的訓練方法， 在這次的作業的例子內 我們使用的是 一個 六層的 fully-connected layer 的 模型 加上 relu的 activation function.","metadata":{"id":"zZvlf0Wv7YdU","cell_id":"00005-c6e202c7-7f31-47c8-80d3-353818257108"}},{"cell_type":"markdown","source":"## Basic Model","metadata":{"id":"fkc3Z-4JYaPe","cell_id":"00006-572c4a0e-110c-4ca7-a6fc-aad17bfd60ad"}},{"cell_type":"code","metadata":{"id":"g8aQRs7ss3nx","cell_id":"00007-95ef991c-871e-4a98-b036-8e75e5be996d","output_cleared":false,"source_hash":"35150ce5","execution_start":1604581110366,"execution_millis":0},"source":"class Model(nn.Module):\n\n  def __init__(self):\n    super(Model, self).__init__()\n    self.fc1 = nn.Linear(3*32*32, 1024)\n    self.fc2 = nn.Linear(1024, 512)\n    self.fc3 = nn.Linear(512, 256)\n    self.fc4 = nn.Linear(256, 128)\n    self.fc5 = nn.Linear(128, 128)\n    self.fc6 = nn.Linear(128, 10)\n    self.relu = nn.ReLU()\n\n  def forward(self, x):\n    x = x.view(-1, 3*32*32)\n    x = self.fc1(x)\n    x = self.relu(x)\n    x = self.fc2(x)\n    x = self.relu(x)\n    x = self.fc3(x)\n    x = self.relu(x)\n    x = self.fc4(x)\n    x = self.relu(x)\n    x = self.fc5(x)\n    x = self.relu(x)\n    x = self.fc6(x)\n    return x\n","execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"以下我們將依序介紹這兩種方法 EWC 跟 MAS ","metadata":{"id":"AfeD8zfAccZe","cell_id":"00008-889174a4-bc75-46a5-942b-0a88f7786551"}},{"cell_type":"markdown","source":"## EWC","metadata":{"id":"qwri0rVpjd6h","cell_id":"00009-580d1e03-b8ee-405d-9951-670494ffd815"}},{"cell_type":"markdown","source":"### Elastic Weight Consolidation\n\n#### 概念\n老師在影片中已經把核心概念介紹給大家，那在這邊我想大家都非常了解了這個方法的概念，我們就直接進入主題\n\n今天我們的任務 是在學習連續的兩個 task task A 跟 task B:\n\n在 EWC 作法下 他的 loss function 會被定義如下\n $$\\mathcal{L}_B = \\mathcal{L}(\\theta) + \\sum_{i} \\frac{\\lambda}{2} F_i (\\theta_{i} - \\theta_{A,i}^{*})^2  $$\n\n先解釋這個 loss function 裡的變數，$\\mathcal{L}_B$ 是指 task B 的 loss, 會等於 正常的loss function $\\mathcal{L}(\\theta)$ (如果 是 classification 的問題,就是 cross entropy 的 loss function) 加上一個正則項 (regularization term) \n\n這個正則項的由兩個部份組成，第一個是 $F_i$ 也是這個方法的核心, 第二個部份是 $(\\theta_{i} - \\theta_{A,i}^{*})^2$  ,  $\\theta_{A,i}^{*}$ 代表的是 訓練完task A 存下來模型第 i 個參數的值, $\\theta_i$ 代表的是目前模型第i個參數的值，注意一點是模型的架構在這種 regularization based 的方法上，都是固定ㄉ，目前模型跟 task A 存下來的模型 架構都一樣只是值不一樣。底下我將說明這個 $F_i$ 是怎麼實做出來\n\n在老師的影片中，老師是以只有兩個參數的模型舉例子，那假設我今天模型就是一個 neural network(參數不只兩個) 該怎麼辦呢？   \n\n$F_i$ 對應到老師的影片敘述是指第i個參數的守衛，假設這個參數對 task A 很重要，那這個 $F_i$ 的值就會很大，這個參數盡量不能被更動...\n\n實際上這個參數的算法 即是 如下的式子\n\n$$ F = [ \\nabla \\log(p(y_n | x_n, \\theta_{A}^{*}) \\nabla \\log(p(y_n | x_n, \\theta_{A}^{*})^T ] $$ \n\n$F$ 之中 只以對角線的值去近似各個參數的 $F_i$ 值\n\n$p(y_n | x_n, \\theta_{A}^{*})$ 指的就是模型在給定之前 task 的 data $x_n$ 以及 給定 訓練完 task A 存下來的模型參數 $\\theta_A^*$ 得到 $y_n$($x_n$ 對應的 label ) 的 posterior probability.\n那統整一下作法就是 再對這個 $p(y_n | x_n, \\theta_{A}^{*})$ 取 log 再取 gradient 並且平方 ( parameter.grad )^2.\n\n每一個參數我都可以使用 pytorch 的 backward 之後再取 gradient 的性質算出各自的 $F_i$.\n\n有關這個 $F$ 其實博大精深，是來自於 fisher information matrix. 底下我放上有關這個lifelong learning 在 fisher information matrix 上是怎麼簡單的近似到這一項，簡單的推導來自 [Continual Learning in Neural\nNetworks](https://arxiv.org/pdf/1910.02718.pdf) 第2.4.1 小節 與 2.4 節\n\nFor You Information: [Elastic Weight Consolidation](https://arxiv.org/pdf/1612.00796.pdf)\n\n\n","metadata":{"id":"e3NePROJyWyW","cell_id":"00010-67ff8127-84a0-401d-a8b4-4908e8becee8"}},{"cell_type":"code","metadata":{"id":"K511GmRzyYWa","cell_id":"00011-836f19e1-6566-49cc-8fdd-e40a281d9342","output_cleared":false,"source_hash":"ddeae49e","execution_millis":0,"execution_start":1604581788126},"source":"\nclass EWC(object):\n  \"\"\"\n    @article{kirkpatrick2017overcoming,\n        title={Overcoming catastrophic forgetting in neural networks},\n        author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},\n        journal={Proceedings of the national academy of sciences},\n        year={2017},\n        url={https://arxiv.org/abs/1612.00796}\n    }\n  \"\"\"\n  def __init__(self, model: nn.Module, dataloaders: list, device):\n    \n    self.model = model\n    self.dataloaders = dataloaders\n    self.device = device\n    \n    self.params = {n: p for n, p in self.model.named_parameters() if p.requires_grad} #抓出模型的所有參數\n    self._means = {} # 初始化 平均參數\n    self._precision_matrices = self._calculate_importance() # 產生 EWC 的 Fisher (F) 矩陣 \n    \n    for n, p in self.params.items():\n      self._means[n] = p.clone().detach() # 算出每個參數的平均 （用之前任務的資料去算平均）\n  \n  def _calculate_importance(self):\n    precision_matrices = {}\n    for n, p in self.params.items(): # 初始化 Fisher (F) 的矩陣（都補零）\n      precision_matrices[n] = p.clone().detach().fill_(0)\n\n    self.model.eval()\n    dataloader_num=len(self.dataloaders)\n    number_data = sum([len(loader) for loader in self.dataloaders])\n    for dataloader in self.dataloaders:\n      for data in dataloader:\n        self.model.zero_grad()\n        input = data[0].to(self.device)\n        output = self.model(input).view(1, -1)\n        label = output.max(1)[1].view(-1)\n        \n        ############################################################################\n        #####                      產生 EWC 的 Fisher(F) 矩陣                    #####\n        ############################################################################    \n        loss = F.nll_loss(F.log_softmax(output, dim=1), label)             \n        loss.backward()                                                    \n                                                                           \n        for n, p in self.model.named_parameters():                         \n            precision_matrices[n].data += p.grad.data ** 2 / number_data   \n                                                                   \n    precision_matrices = {n: p for n, p in precision_matrices.items()}\n    return precision_matrices\n\n  def penalty(self, model: nn.Module):\n    loss = 0\n    for n, p in model.named_parameters():\n      _loss = self._precision_matrices[n] * (p - self._means[n]) ** 2\n      loss += _loss.sum()\n    return loss\n","execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## MAS","metadata":{"id":"jmsPw6avjl5B","cell_id":"00012-d0eed295-f7e3-4477-ba43-2979c2af8c53"}},{"cell_type":"markdown","source":"### Memory Aware Synapses\n概念:\n老師的影片中，將它歸類到和 EWC 一樣的方法，只是算這個 important weight 的方式不太一樣.底下我將說明這個方法該怎麼實做\n\nMAS:\n在 MAS 內，學習一個連續的 tasks, task A, 和 task B, 他的 loss function 定義如下:\n\n$$\\mathcal{L}_B = \\mathcal{L}(\\theta) + \\sum_{i} \\frac{\\lambda}{2} \\Omega_i (\\theta_{i} - \\theta_{A,i}^{*})^2$$\n\n和 ewc不同的是 式子中的 $F_i$ 被取代成 $\\Omega_i$ , $\\Omega_i$ 來自於以下的式子：\n\n$$\\Omega_i = || \\frac{\\partial \\ell_2^2(M(x_k; \\theta))}{\\partial \\theta_i} || $$ \n\n$x_k$ 是 來自於 前面 task 的 sample data。 式子上的作法就是對最後模型的 output vector (最後一層)做 l2 norm 後取平方 再對各自的weight微分(取gradient) 並且取 該 gradient 的絕對值，在該paper 中其實也可以對各個層的 output vector 做 l2 norm ( local 版本)，這邊只實做 global 的版本。\n\n\nFor Your Information: \n[Memory Aware Synapses](https://arxiv.org/pdf/1711.09601.pdf)\n \n\n\n\n\n","metadata":{"id":"C7fSYpALrAVw","cell_id":"00013-a3761ef1-31a8-40d5-a105-8f11a93e1aa7"}},{"cell_type":"code","metadata":{"id":"btFvFJMmqxE0","cell_id":"00014-45a8190e-c334-471f-93a9-440836ae8204","output_cleared":false,"source_hash":"fb6ee11f","execution_start":1604630240845,"execution_millis":0},"source":"\nclass MAS(object):\n    \"\"\"\n    @article{aljundi2017memory,\n      title={Memory Aware Synapses: Learning what (not) to forget},\n      author={Aljundi, Rahaf and Babiloni, Francesca and Elhoseiny, Mohamed and Rohrbach, Marcus and Tuytelaars, Tinne},\n      booktitle={ECCV},\n      year={2018},\n      url={https://eccv2018.org/openaccess/content_ECCV_2018/papers/Rahaf_Aljundi_Memory_Aware_Synapses_ECCV_2018_paper.pdf}\n    }\n    \"\"\"\n    def __init__(self, model: nn.Module, dataloaders: list, device):\n        self.model = model \n        self.dataloaders = dataloaders\n        self.params = {n: p for n, p in self.model.named_parameters() if p.requires_grad} #抓出模型的所有參數\n        self._means = {} # 初始化 平均參數\n        self.device = device\n        self._precision_matrices = self.calculate_importance() # 產生 MAS 的 Omega(Ω) 矩陣\n    \n        for n, p in self.params.items():\n            self._means[n] = p.clone().detach()\n    \n    def calculate_importance(self):\n        print('Computing MAS')\n\n        precision_matrices = {}\n        for n, p in self.params.items():\n            precision_matrices[n] = p.clone().detach().fill_(0) # 初始化 Omega(Ω) 矩陣（都補零）\n\n        self.model.eval()\n        dataloader_num = len(self.dataloaders)\n        num_data = sum([len(loader) for loader in self.dataloaders])\n        for dataloader in self.dataloaders:\n            for data in dataloader:\n                self.model.zero_grad()\n                output = self.model(data[0].to(self.device))\n\n                #######################################################################################\n                #####  產生 MAS 的 Omega(Ω) 矩陣 ( 對 output 向量 算他的 l2 norm 的平方) 再取 gradient  ####\n                #######################################################################################\n                output.pow_(2)                                                   \n                loss = torch.sum(output,dim=1)                                   \n                loss = loss.mean()                                               \n                loss.backward()                                                  \n                                          \n                for n, p in self.model.named_parameters():                      \n                    precision_matrices[n].data += p.grad.abs() / num_data ## difference with EWC      \n\n        precision_matrices = {n: p for n, p in precision_matrices.items()}\n        return precision_matrices\n\n    def penalty(self, model: nn.Module):\n        loss = 0\n        for n, p in model.named_parameters():\n            _loss = self._precision_matrices[n] * (p - self._means[n]) ** 2\n            loss += _loss.sum()\n        return loss","execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# 資料","metadata":{"id":"NWQ_JBlbFnKV","cell_id":"00015-120eccab-4cf6-4d92-87b2-019ee7bc2f0b"}},{"cell_type":"markdown","source":"## 資料預處理\n- 轉換 MNIST  ($1*28*28$) 到 ($3*32*32$)\n- 轉換 USPS   ($1*16*16$) 到 ($3*32*32$)\n- 正規化 圖片","metadata":{"id":"vdep_aMvUYqI","cell_id":"00016-ed9d7a76-27c4-445a-bd0d-147410b6278f"}},{"cell_type":"code","metadata":{"id":"xVHrWsHfIPtY","cell_id":"00017-92005e35-f293-4759-a622-6db8b27b1450","output_cleared":false,"source_hash":"bddcff31","execution_start":1604630244272,"execution_millis":1},"source":"class Convert2RGB(object):\n  \n  def __init__(self, num_channel):\n    self.num_channel = num_channel\n\n  def __call__(self, img):                                                                                                                                                                                                                              \n    # If the channel of img is not equal to desired size,\n    # then expand the channel of img to desired size.\n    img_channel = img.size()[0]\n    img = torch.cat([img] * (self.num_channel - img_channel + 1), 0)\n    return img\n\n\nclass Pad(object):\n\n  def __init__(self, size, fill=0, padding_mode='constant'):\n    self.size = size\n    self.fill = fill\n    self.padding_mode = padding_mode\n    \n  def __call__(self, img):\n    # If the H and W of img is not equal to desired size,\n    # then pad the channel of img to desired size.\n    img_size = img.size()[1]\n    assert ((self.size - img_size) % 2 == 0)\n    padding = (self.size - img_size) // 2\n    padding = (padding, padding, padding, padding)\n    return F.pad(img, padding, self.padding_mode, self.fill)\n\ndef get_transform():\n  transform = transforms.Compose([transforms.ToTensor(),\n                                  Pad(32),\n                                  Convert2RGB(3),\n                                  transforms.Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5])])\n  return transform\n","execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## 準備 資料集\n- MNIST   : 一張圖片資料大小:  $28*28*1$, 灰階 , 10 個種類\n- SVHN    : 一張圖片資料大小:  $32*32*3$, RGB , 10 個種類\n- USPS    : 一張圖片資料大小:  $16*16*1$, 灰階 , 10 個種類","metadata":{"id":"PW4r9Jd-etyG","cell_id":"00018-9c3436c6-e49e-46e1-9e44-790ab7500b12"}},{"cell_type":"code","metadata":{"id":"HPIeRDtIox0M","cell_id":"00019-fbac028f-1129-4d12-8e5d-ec63fd533c72","output_cleared":false,"source_hash":"ec6a75f","execution_start":1604630248239,"execution_millis":3},"source":"class Data():\n\n  def __init__(self, path):\n\n    transform = get_transform()\n\n    self.MNIST_dataset = datasets.MNIST(root = os.path.join(path, \"MNIST\"),\n                                        transform=transform,\n                                        train = True,\n                                        download = True)\n\n    self.SVHN_dataset = datasets.SVHN(root = os.path.join(path, \"SVHN\"),\n                                      transform=transform,\n                                      split='train',\n                                      download = True)\n\n    self.USPS_dataset = datasets.USPS(root = os.path.join(path, \"USPS\"),\n                                            transform=transform,\n                                            train = True,\n                                            download = True)\n    \n  def get_datasets(self):\n      a = [(self.SVHN_dataset, \"SVHN\"),(self.MNIST_dataset, \"MNIST\"),(self.USPS_dataset, \"USPS\")]\n      return a\n","execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## 建立 Dataloader\n- *.train_loader: 拿取訓練集並訓練 \\\\\n- *.val_loader: 拿取驗證集並驗測結果 \\\\","metadata":{"id":"eMtV82EPjsld","cell_id":"00020-4575b865-eabb-4ad3-af92-edb58af8831b"}},{"cell_type":"code","metadata":{"id":"29-5g8ZHjs_3","cell_id":"00021-f612b082-d589-44c5-a614-c76c02aed61f","output_cleared":false,"source_hash":"d4041783","execution_start":1604630258857,"execution_millis":4},"source":"class Dataloader():\n\n  def __init__(self, dataset, batch_size, split_ratio=0.1):\n    self.dataset = dataset[0]\n    self.name = dataset[1]\n    train_sampler, val_sampler = self.split_dataset(split_ratio)\n\n    self.train_dataset_size = len(train_sampler)\n    self.val_dataset_size = len(val_sampler)\n\n    self.train_loader = data.DataLoader(self.dataset, batch_size = batch_size, sampler=train_sampler)\n    self.val_loader = data.DataLoader(self.dataset, batch_size = batch_size, sampler=val_sampler)\n    self.train_iter = self.infinite_iter()\n\n  def split_dataset(self, split_ratio):\n    data_size = len(self.dataset)\n    split = int(data_size * split_ratio)\n    indices = list(range(data_size))\n    np.random.shuffle(indices)\n    train_idx, valid_idx = indices[split:], indices[:split]\n\n    train_sampler = sampler.SubsetRandomSampler(train_idx)\n    val_sampler = sampler.SubsetRandomSampler(valid_idx)\n    return train_sampler, val_sampler\n    \n  def infinite_iter(self):\n    it = iter(self.train_loader)\n    while True:\n      try:\n        ret = next(it)\n        yield ret\n      except StopIteration:\n        it = iter(self.train_loader)\n","execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# 小工具","metadata":{"id":"vzG5BWtHGA3p","cell_id":"00022-33e37c13-e17e-4d09-9262-f6ff2af99589"}},{"cell_type":"markdown","source":"## 儲存模型","metadata":{"id":"vMBoCSH5MBLN","cell_id":"00023-393db76d-acf5-4877-a6aa-891ef89c2506"}},{"cell_type":"code","metadata":{"id":"uCZuQrWiMGmH","cell_id":"00024-040b0162-c68a-4bdb-897b-16693038cade","output_cleared":false,"source_hash":"ba48cd1","execution_start":1604630280008,"execution_millis":1},"source":"def save_model(model, optimizer, store_model_path):\n  # save model and optimizer\n  torch.save(model.state_dict(), f'{store_model_path}.ckpt')\n  torch.save(optimizer.state_dict(), f'{store_model_path}.opt')\n  return\n","execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"##載入模型\n","metadata":{"id":"Nde98xvAMxAd","cell_id":"00025-5ce52029-4555-4769-86e2-b709fd118818"}},{"cell_type":"code","metadata":{"id":"FGzZ2Yp2MxK-","cell_id":"00026-0cefa0ae-92dd-4e3d-a828-00e8d15bef6c","output_cleared":false,"source_hash":"d991dbdb","execution_start":1604630284874,"execution_millis":1},"source":"def load_model(model, optimizer, load_model_path):\n  # load model and optimizer\n  print(f'Load model from {load_model_path}')\n  model.load_state_dict(torch.load(f'{load_model_path}.ckpt'))\n  optimizer.load_state_dict(torch.load(f'{load_model_path}.opt'))\n  return model, optimizer\n","execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## 建立模型 & 優化器","metadata":{"id":"eoz6awEcOIAz","cell_id":"00027-46f7b1f9-88d7-4ba2-9991-fd7b44b75774"}},{"cell_type":"code","metadata":{"id":"TvWqv_JlOOix","cell_id":"00028-5ef30e21-cf26-4417-8139-f5b0fa273134","output_cleared":false,"source_hash":"1ef255c","execution_start":1604630292415,"execution_millis":10},"source":"def build_model(data_path, batch_size, learning_rate): \n  # create model\n  model = Model().to(device)\n  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n  data = Data(data_path)\n  datasets = data.get_datasets()\n  tasks = []\n  for dataset in datasets:\n    tasks.append(Dataloader(dataset, batch_size))\n\n  return model, optimizer, tasks\n","execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# 訓練","metadata":{"id":"74De0sS-O50R","cell_id":"00029-03956a04-5d1c-412c-b67c-8e7ce36f6d23"}},{"cell_type":"markdown","source":"## 正常訓練 ( baseline )","metadata":{"id":"_q9Co3vuGWfu","cell_id":"00030-24af5e68-621c-418d-bffb-d1b1730f8c3f"}},{"cell_type":"code","metadata":{"id":"TBnE9GbiO8Ob","cell_id":"00031-bd638970-1789-4169-ae6e-620bb7bbd4ba","output_cleared":false,"source_hash":"8be357b7","execution_start":1604630301869,"execution_millis":12},"source":"def normal_train(model, optimizer, task, total_epochs, summary_epochs):\n  model.train()\n  model.zero_grad()\n  ceriation = nn.CrossEntropyLoss()\n  losses = []\n  loss = 0.0\n  for epoch in range(summary_epochs):\n    imgs, labels = next(task.train_iter)\n    imgs, labels = imgs.to(device), labels.to(device)\n    outputs = model(imgs)\n    ce_loss = ceriation(outputs, labels)\n    \n    optimizer.zero_grad()\n    ce_loss.backward()\n    optimizer.step()\n\n    loss += ce_loss.item()\n    if (epoch + 1) % 50 == 0:\n      loss = loss / 50\n      print (\"\\r\", \"train task {} [{}] loss: {:.3f}      \".format(task.name, (total_epochs + epoch + 1), loss), end=\" \")\n      losses.append(loss)\n      loss = 0.0\n    \n  return model, optimizer, losses\n  ","execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## EWC 訓練","metadata":{"id":"m2FlojHR_4qb","cell_id":"00032-e2f54e0c-6734-429a-af9e-d1e9389b369c"}},{"cell_type":"code","metadata":{"id":"nLHALesw_61i","cell_id":"00033-e7259efb-3f1a-459e-ad52-41e9909fbaa1","output_cleared":false,"source_hash":"af979218","execution_start":1604630491320,"execution_millis":1},"source":"def ewc_train(model, optimizer, task, total_epochs, summary_epochs, ewc, lambda_ewc):\n  model.train()\n  model.zero_grad()\n  ceriation = nn.CrossEntropyLoss()\n  losses = []\n  loss = 0.0\n  for epoch in range(summary_epochs):\n    imgs, labels = next(task.train_iter)\n    imgs, labels = imgs.to(device), labels.to(device)\n    outputs = model(imgs)\n    ce_loss = ceriation(outputs, labels)\n    total_loss = ce_loss\n    ewc_loss = ewc.penalty(model)\n    total_loss += lambda_ewc * ewc_loss \n    \n    optimizer.zero_grad()\n    total_loss.backward()\n    optimizer.step()\n\n    loss += total_loss.item()\n    if (epoch + 1) % 50 == 0:\n      loss = loss / 50\n      print (\"\\r\", \"train task {} [{}] loss: {:.3f}      \".format(task.name, (total_epochs + epoch + 1), loss), end=\" \")\n      losses.append(loss)\n      loss = 0.0\n    \n  return model, optimizer, losses","execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## MAS 訓練","metadata":{"id":"0B6to7GuqvPX","cell_id":"00034-119bb58a-55ee-4179-8c3f-7a9c50e23389"}},{"cell_type":"code","metadata":{"id":"fWhZz9uZquew","cell_id":"00035-2671919c-702b-4c3d-9375-e7e16402edd8","output_cleared":false,"source_hash":"d596fbfc","execution_start":1604630494713,"execution_millis":40},"source":"def mas_train(model, optimizer, task, total_epochs, summary_epochs, mas_tasks, lambda_mas,alpha=0.8):\n  model.train()\n  model.zero_grad()\n  ceriation = nn.CrossEntropyLoss()\n  losses = []\n  loss = 0.0\n  for epoch in range(summary_epochs):\n    imgs, labels = next(task.train_iter)\n    imgs, labels = imgs.to(device), labels.to(device)\n    outputs = model(imgs)\n    ce_loss = ceriation(outputs, labels)\n    total_loss = ce_loss\n    mas_tasks.reverse()\n    if len(mas_tasks) > 1:\n        preprevious = 1 - alpha\n        scalars = [alpha,preprevious]\n        for mas,scalar in zip(mas_tasks[:2],scalars):\n            mas_loss = mas.penalty(model)\n            total_loss += lambda_mas * mas_loss * scalar\n    elif len(mas_tasks) == 1:\n        mas_loss = mas_tasks[0].penalty(model)\n        total_loss += lambda_mas * mas_loss\n    else:\n        pass\n    \n    optimizer.zero_grad()\n    total_loss.backward()\n    optimizer.step()\n\n    loss += total_loss.item()\n    if (epoch + 1) % 50 == 0:\n      loss = loss / 50\n      print (\"\\r\", \"train task {} [{}] loss: {:.3f}      \".format(task.name, (total_epochs + epoch + 1), loss), end=\" \")\n      losses.append(loss)\n      loss = 0.0\n    \n  return model, optimizer, losses","execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## 驗證\n","metadata":{"id":"6cuHVXxAfHrA","cell_id":"00036-8b11447d-c5d3-492b-8ee2-76cf43912c8b"}},{"cell_type":"code","metadata":{"id":"ZBp-n3FrfOCe","cell_id":"00037-7ce5beee-3f6a-4cfd-8cd3-5d7b69c0a0c4","output_cleared":false,"source_hash":"38c66102","execution_start":1604630587161,"execution_millis":0},"source":"def val(model, task):\n  model.eval()\n  correct_cnt = 0\n  for imgs, labels in task.val_loader:\n    imgs, labels = imgs.to(device), labels.to(device)\n    outputs = model(imgs)\n    _, pred_label = torch.max(outputs.data, 1)\n\n    correct_cnt += (pred_label == labels.data).sum().item()\n    \n  return correct_cnt / task.val_dataset_size\n","execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## 主訓練程序\n","metadata":{"id":"dFEYmPAlx_SX","cell_id":"00038-95a1c928-f0ce-4cb3-af7a-d69fc3243169"}},{"cell_type":"code","metadata":{"id":"cJ54vDP2yC2S","cell_id":"00039-30271b4f-51b4-4803-97a5-99a06c5ef310","output_cleared":false,"source_hash":"a5ec39","execution_start":1604630616524,"execution_millis":1},"source":"def train_process(model, optimizer, tasks, config):\n  task_loss, acc = {}, {}\n  for task_id, task in enumerate(tasks):\n    print ('\\n')\n    total_epochs = 0\n    task_loss[task.name] = []\n    acc[task.name] = []\n    if config.mode == 'basic' or task_id == 0:\n      while (total_epochs < config.num_epochs):\n        model, optimizer, losses = normal_train(model, optimizer, task, total_epochs, config.summary_epochs)\n        task_loss[task.name] +=  losses\n\n        for subtask in range(task_id + 1):\n          acc[tasks[subtask].name].append(val(model, tasks[subtask]))\n\n        total_epochs += config.summary_epochs\n        if total_epochs % config.store_epochs == 0 or total_epochs >= config.num_epochs:\n          save_model(model, optimizer, config.store_model_path)\n    \n    if config.mode == 'ewc' and task_id > 0:\n      old_dataloaders = []\n      for old_task in range(task_id): \n        old_dataloaders += [tasks[old_task].val_loader]\n      ewc = EWC(model, old_dataloaders, device)\n      while (total_epochs < config.num_epochs):\n        model, optimizer, losses = ewc_train(model, optimizer, task, total_epochs, config.summary_epochs, ewc, config.lifelong_coeff)\n        task_loss[task.name] +=  losses\n\n        for subtask in range(task_id + 1):\n          acc[tasks[subtask].name].append(val(model, tasks[subtask]))\n\n        total_epochs += config.summary_epochs\n        if total_epochs % config.store_epochs == 0 or total_epochs >= config.num_epochs:\n          save_model(model, optimizer, config.store_model_path)\n\n    if config.mode == 'mas' and task_id > 0:\n      old_dataloaders = []\n      mas_tasks = []\n      for old_task in range(task_id): \n        old_dataloaders += [tasks[old_task].val_loader]\n        mas = MAS(model, old_dataloaders, device)\n        mas_tasks += [mas]\n      while (total_epochs < config.num_epochs):\n        model, optimizer, losses = mas_train(model, optimizer, task, total_epochs, config.summary_epochs, mas_tasks, config.lifelong_coeff)\n        task_loss[task.name] +=  losses\n\n        for subtask in range(task_id + 1):\n          acc[tasks[subtask].name].append(val(model, tasks[subtask]))\n\n        total_epochs += config.summary_epochs\n        if total_epochs % config.store_epochs == 0 or total_epochs >= config.num_epochs:\n          save_model(model, optimizer, config.store_model_path)\n\n    if config.mode == 'scp' and task_id > 0:\n      pass\n      ########################################\n      ##       TODO 區塊 （ PART 2 ）         ##\n      ########################################\n      ##    PART 2  implementation 的部份    ##\n      ##   你也可以寫別的 regularization 方法  ##\n      ##    助教這裡有提供的是  scp    的 作法   ##\n      ##     Slicer Cramer Preservation     ##\n      ########################################\n      ########################################\n      ##       TODO 區塊 （ PART 2 ）         ##\n      ########################################\n  return task_loss, acc\n","execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# 設定","metadata":{"id":"7PbfgB3n9eoT","cell_id":"00040-5a72a63c-a9eb-4e8e-a470-5ad25ca83acc"}},{"cell_type":"code","metadata":{"id":"3kWSZ4w39gzj","cell_id":"00041-5bcc16f2-f36a-4188-9d26-cf53ae95d5af","output_cleared":false,"source_hash":"1912f51f","execution_start":1604630703423,"execution_millis":0},"source":" class configurations(object):\n  def __init__(self):\n    self.batch_size = 256\n    self.num_epochs = 10000\n    self.store_epochs = 250\n    self.summary_epochs = 250\n    self.learning_rate = 0.0005\n    self.load_model = False\n    self.store_model_path = \"./model\"\n    self.load_model_path = \"./model\"\n    self.data_path = \"./data\"\n    self.mode = None\n    self.lifelong_coeff = 0.5\n\n###### 你也可以自己設定參數   ########\n###### 但上面的參數 是這次作業的預設直 #########\n","execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"#主程式區塊\n- 給 EWC, MAS 超參數 $\\lambda$ \n- 訓練","metadata":{"id":"w464f4KOLUh6","cell_id":"00042-75b0bf89-680f-4ab1-a42c-cc3fa119e223"}},{"cell_type":"code","metadata":{"id":"AJwVkorvLaSh","outputId":"d13d513a-fa13-45ae-b198-93e268c26844","colab":{"base_uri":"https://localhost:8080/","height":620,"referenced_widgets":["5dbf0aad2f184ed28d62aa04a3917234","e2299cb5c0434fa4b395616d44132f46","2548b480d28140269d7adedbafd37b00","2fa26176e4f04676a16d96c34590b80b","3d8a611f75984668849c47d8da55c774","1844220894384aaba01101c5dcb19557","e36fb5d801924c998d9b9daae1fea23f","72720e80c66f440ea75beac862cf94dc","57c35378a81f420da7c84d9067acefbb","a7d54badc91f4d8b91e7b2d7d0a05417","d09ecbd109a5431baa472da46739dc8f","f04e98e5a2e14712aa7fe11894cfde20","20101d312f1a423da807b3e2000a425b","ab1480fe2bdd41f0aa31cbb7e3da4846","31013f55b5ec459697fcd5052583dcfd","104e0c9743d44f01b15b2fe0c5d8ef6c","ef63806fa39b43b18b5422581d491ca9","f2f9463db89d41f193a36b148edeedf9","e7c44691fc2a49dcaa92c0778053e726","1d518c4702a54c4cbf732744cb9d2cdf","631d9df8d22d45d2b6ec4ac50e996498","f14b0c6c6d1246269d5854c9b8d0d08d","36a70cefd0bb4dbf8f4c79d6ba4b24f5","d2a80e1f21c34f32bbdbc16f5dde67ef","f3522a02d6944613a65075a68381aa86","334b6c92e01842b4a7fe6dfc9153ff7f","ff04a5d339754fd29a309b278385e9dd","75947f9968b54fefb703584af8c9a3c1","ce329a663ab84dafbb427c6b277492f3","d5b0ae3de4264eb4829664ef4bc66c8f","debfda6eb9434892a08f976220fdfc0f","69912206ffa54a56b611313cc634ee6f","8deb94ae3b444b23b580d7d5195d7241","80b8ac5c04d445908b0b2399903bb461","ee39da8708b440de8aeec8e443a625cf","cbee9e60f88d4c65acff7e3d4b34cebb","e0672f84471c432e97d3ee0a3778160b","b6a8c684aa3b48ef8f9cca753425160b","2e0fb2872ab74a72a1303e3367e02541","47dfd8f131d447d78501bf6764aa4302","d104590766044ec99b4f3204541f0341","a311d9659c69406c9844808aa350cdec","e097d751aeae4728b5e52e22609af0b2","a390d0895f1f4f1f9f6e1fac8141ad5d","90fce40fad49400ab68ddbc7a1fe4acb","d0238c567d654efc82b4ae72e08311a0","978244e695d845ff871766cda896306a","94817180afbf46009db7b2f1c652eb7d"]},"cell_id":"00043-bca59312-65f1-436f-b2cc-c40d3b456dc6","output_cleared":false,"source_hash":"10d7393","execution_start":1604630713807},"source":"\"\"\"\nthe order is svhn -> mnist -> usps\n===============================================\n\n\"\"\"\n# import tqdm\n\nif __name__ == '__main__':\n    mode_list = ['mas','ewc','basic']\n\n    ## hint: 謹慎的去選擇 lambda 超參數 / ewc: 80~400, mas: 0.1 - 10\n    ############################################################################\n    #####                           TODO 區塊 （ PART 1 ）                   #####\n    ############################################################################ \n    coeff_list = [0, 0 ,0 ]  ## 你需要在這 微調 lambda 參數, mas, ewc, baseline=0##  \n    ############################################################################\n    #####                           TODO 區塊 （ PART 1 ）                   #####\n    ############################################################################ \n    \n    config = configurations()\n    count = 0\n    for mode in mode_list:\n        config.mode = mode\n        config.lifelong_coeff = coeff_list[count]\n        print(\"{} training\".format(config.mode))    \n        model, optimizer, tasks = build_model(config.data_path, config.batch_size, config.learning_rate)\n        print (\"Finish build model\")\n        if config.load_model:\n            model, optimizer = load_model(model, optimizer, config.load_model_path)\n        task_loss, acc = train_process(model, optimizer, tasks, config)\n        with open(f'./{config.mode}_acc.txt', 'w') as f:\n            json.dump(acc, f)\n        count += 1\n","execution_count":null,"outputs":[{"name":"stdout","text":"mas training\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/MNIST/raw/train-images-idx3-ubyte.gz\n100.1%Extracting ./data/MNIST/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/MNIST/raw\n0.0%Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz\nExtracting ./data/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz\n26.8%","output_type":"stream"}]},{"cell_type":"markdown","source":"# 畫出 Result 圖片","metadata":{"id":"DSJX338dA2He","cell_id":"00044-1cb56532-57fa-45f6-86d1-324867a99fbe"}},{"cell_type":"code","metadata":{"id":"4X_RvV4my5Jl","cell_id":"00045-f72ace30-00c8-4742-b60b-9a48ceeb1e9b"},"source":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\n\n\ndef plot_result(mode_list, task1, task2, task3):\n  \n    #draw the lines\n    count = 0\n    for reg_name in mode_list:\n        label = reg_name\n        with open(f'./{reg_name}_acc.txt', 'r') as f:\n            acc = json.load(f)\n        if count == 0: \n            color= 'red'\n        elif count  == 1:\n            color= 'blue'\n        else:\n            color = 'purple'\n        ax1=plt.subplot(3, 1, 1)\n        plt.plot(range(len(acc[task1])),acc[task1],color,label=label)\n        ax1.set_ylabel(task1)\n        ax2=plt.subplot(3, 1, 2,sharex=ax1,sharey=ax1)\n        plt.plot(range(len(acc[task3]),len(acc[task1])),acc[task2],color,label=label)\n        ax2.set_ylabel(task2)\n        ax3=plt.subplot(3, 1, 3,sharex=ax1,sharey=ax1)\n        ax3.set_ylabel(task3)\n        plt.plot(range(len(acc[task2]),len(acc[task1])),acc[task3],color,label=label)\n        count += 1\n    plt.ylim((0.02,1.02))\n    plt.legend()\n    plt.show()\n    return \n\nmode_list = ['ewc','mas','basic']\nplot_result(mode_list,'SVHN','MNIST','USPS')","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"在今年 ICLR 2020 的 paper，有以這兩種方法做 baseline，並對這兩種方法各自做了一個 geometry view，也提出新的方法，有興趣的人可以參考\n\npaper link 如下 [SLICED CRAMER´ SYNAPTIC CONSOLIDATION FOR\nPRESERVING DEEPLY LEARNED REPRESENTATIONS](https://openreview.net/pdf?id=BJge3TNKwH)","metadata":{"id":"43QGlXTxyzw_","cell_id":"00046-771f4886-afe1-4a1e-97c9-be45f2a87ca6"}},{"cell_type":"markdown","source":"# 進階 \n請實做其他的 regularization 的方法，助教有提供的是 SCP 的作法，\n\n你也可以考慮實做出 SI, Rimennian Walk, IMM, 或是上面的方法, \n\n你可以參考助教上方的寫法，寫出雷同的 class 跟 training 來 train，\n\n記得畫出與上方雷同的 evaluation 圖表 (show result) example 需要比對的話 可以參考助教給的 slide。\n","metadata":{"id":"cbMUPaN_zAs7","cell_id":"00047-aaccdb4c-4dbe-4ab0-962d-a4000c528bcd"}},{"cell_type":"code","metadata":{"id":"m3aOQ2XI-Prm","cell_id":"00048-089a31df-7b17-4ffb-a280-b80a02c4403b"},"source":"def sample_spherical(npoints, ndim=3):\n    vec = np.random.randn(ndim, npoints)\n    vec /= np.linalg.norm(vec, axis=0)\n    return vec","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bcjtln1T6U7T","cell_id":"00049-b553f117-49a9-45b7-985d-2a89e9897cc5"},"source":"class SCP(object):\n    \"\"\"\n    OPEN REVIEW VERSION:\n    https://openreview.net/forum?id=BJge3TNKwH\n    \"\"\"\n    def __init__(self, model: nn.Module, dataloaders: list, L: int, device):\n        self.model = model \n        self.dataloaders = dataloaders\n        self.params = {n: p for n, p in self.model.named_parameters() if p.requires_grad}\n        self._means = {}\n        self.L= L\n        self.device = device\n        self._precision_matrices = self.calculate_importance()\n    \n        for n, p in self.params.items():\n            self._means[n] = p.clone().detach()\n    \n    def calculate_importance(self):\n        print('Computing SCP')\n\n        precision_matrices = {}\n        for n, p in self.params.items():\n            precision_matrices[n] = p.clone().detach().fill_(0)\n\n        self.model.eval()\n        dataloader_num = len(self.dataloaders)\n        num_data = sum([len(loader) for loader in self.dataloaders])\n        for dataloader in self.dataloaders:\n            for data in dataloader:\n                self.model.zero_grad()\n                output = self.model(data[0].to(self.device))\n\n                ####################################################################################\n                #####                            TODO 區塊 （ PART 2 ）                           #####\n                ####################################################################################\n                ##### 產生 SCP 的 Gamma(Γ) 矩陣（ 如同 MAS 的 Omega(Ω) 矩陣, EWC 的 Fisher(F) 矩陣 ）#####\n                ####################################################################################\n                #####        1.對所有資料的 Output vector 取 平均 得到 平均 vector φ(:,θ_A* )       #####\n                ####################################################################################\n\n                ####################################################################################\n                #####   2. 隨機 從 單位球殼 取樣 L 個 vector ξ #（ Hint: sample_spherical() ）      #####\n                ####################################################################################\n\n                ####################################################################################\n                #####   3.    每一個 vector ξ 和 vector φ( :,θ_A* )內積得到 scalar ρ               #####\n                #####           對 scalar ρ 取 backward ， 每個參數得到各自的 gradient ∇ρ           #####\n                #####       每個參數的 gradient ∇ρ 取平方 取 L 平均 得到 各個參數的 Γ scalar          #####  \n                #####              所有參數的  Γ scalar 組合而成其實就是 Γ 矩陣                      #####\n                ####(hint: 記得 每次 backward 之後 要 zero_grad 去 清 gradient, 不然 gradient會累加 )######   \n                ####################################################################################\n      \n                ####################################################################################      \n                #####                            TODO 區塊 （ PART 2 ）                          #####\n                ####################################################################################\n\n        precision_matrices = {n: p for n, p in precision_matrices.items()}\n        return precision_matrices\n\n    def penalty(self, model: nn.Module):\n        loss = 0\n        for n, p in model.named_parameters():\n            _loss = self._precision_matrices[n] * (p - self._means[n]) ** 2\n            loss += _loss.sum()\n        return loss","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tp6EbyrhXoAH","cell_id":"00050-ddd768e0-c825-447f-8146-d98c4b887646"},"source":"def scp_train(model, optimizer, task, total_epochs, summary_epochs, scp_tasks, lambda_scp,alpha=0.65):\n  losses = []\n  loss = 0.0\n  ###############################\n  #####  TODO 區塊 （PART 2） #####\n  ###############################\n  ##  參考 MAS. EWC train 的寫法 ##                 \n  ###############################\n  #####  TODO 區塊 （PART 2） #####\n  ###############################\n  return model, optimizer, losses","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V1PxP2W3ZcrV","cell_id":"00051-f03cf635-81cc-410b-b329-e9ad3a62dfb6"},"source":"# if __name__ == \"__main__\": \n#   pass \n###############################\n#####  TODO 區塊 （PART 2） #####\n###############################\n##     參考 main 區塊一樣       ##                 \n##     的 code 結合新方法       ##\n###############################\n#####  TODO 區塊 （PART 2） #####\n###############################","execution_count":null,"outputs":[]}],"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hw14_life_long_learning.ipynb","provenance":[],"collapsed_sections":["LD5roJkIvoRj"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"5dbf0aad2f184ed28d62aa04a3917234":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e2299cb5c0434fa4b395616d44132f46","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2548b480d28140269d7adedbafd37b00","IPY_MODEL_2fa26176e4f04676a16d96c34590b80b"]}},"e2299cb5c0434fa4b395616d44132f46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2548b480d28140269d7adedbafd37b00":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3d8a611f75984668849c47d8da55c774","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1844220894384aaba01101c5dcb19557"}},"2fa26176e4f04676a16d96c34590b80b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e36fb5d801924c998d9b9daae1fea23f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9920512/? [00:08&lt;00:00, 1157254.27it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_72720e80c66f440ea75beac862cf94dc"}},"3d8a611f75984668849c47d8da55c774":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1844220894384aaba01101c5dcb19557":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e36fb5d801924c998d9b9daae1fea23f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"72720e80c66f440ea75beac862cf94dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"57c35378a81f420da7c84d9067acefbb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a7d54badc91f4d8b91e7b2d7d0a05417","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d09ecbd109a5431baa472da46739dc8f","IPY_MODEL_f04e98e5a2e14712aa7fe11894cfde20"]}},"a7d54badc91f4d8b91e7b2d7d0a05417":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d09ecbd109a5431baa472da46739dc8f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_20101d312f1a423da807b3e2000a425b","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ab1480fe2bdd41f0aa31cbb7e3da4846"}},"f04e98e5a2e14712aa7fe11894cfde20":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_31013f55b5ec459697fcd5052583dcfd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 32768/? [00:11&lt;00:00, 79038.78it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_104e0c9743d44f01b15b2fe0c5d8ef6c"}},"20101d312f1a423da807b3e2000a425b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ab1480fe2bdd41f0aa31cbb7e3da4846":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"31013f55b5ec459697fcd5052583dcfd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"104e0c9743d44f01b15b2fe0c5d8ef6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ef63806fa39b43b18b5422581d491ca9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f2f9463db89d41f193a36b148edeedf9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e7c44691fc2a49dcaa92c0778053e726","IPY_MODEL_1d518c4702a54c4cbf732744cb9d2cdf"]}},"f2f9463db89d41f193a36b148edeedf9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e7c44691fc2a49dcaa92c0778053e726":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_631d9df8d22d45d2b6ec4ac50e996498","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f14b0c6c6d1246269d5854c9b8d0d08d"}},"1d518c4702a54c4cbf732744cb9d2cdf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_36a70cefd0bb4dbf8f4c79d6ba4b24f5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1654784/? [00:20&lt;00:00, 638394.45it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d2a80e1f21c34f32bbdbc16f5dde67ef"}},"631d9df8d22d45d2b6ec4ac50e996498":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f14b0c6c6d1246269d5854c9b8d0d08d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"36a70cefd0bb4dbf8f4c79d6ba4b24f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d2a80e1f21c34f32bbdbc16f5dde67ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f3522a02d6944613a65075a68381aa86":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_334b6c92e01842b4a7fe6dfc9153ff7f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ff04a5d339754fd29a309b278385e9dd","IPY_MODEL_75947f9968b54fefb703584af8c9a3c1"]}},"334b6c92e01842b4a7fe6dfc9153ff7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ff04a5d339754fd29a309b278385e9dd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ce329a663ab84dafbb427c6b277492f3","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d5b0ae3de4264eb4829664ef4bc66c8f"}},"75947f9968b54fefb703584af8c9a3c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_debfda6eb9434892a08f976220fdfc0f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 8192/? [00:00&lt;00:00, 13266.69it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_69912206ffa54a56b611313cc634ee6f"}},"ce329a663ab84dafbb427c6b277492f3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d5b0ae3de4264eb4829664ef4bc66c8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"debfda6eb9434892a08f976220fdfc0f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"69912206ffa54a56b611313cc634ee6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8deb94ae3b444b23b580d7d5195d7241":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_80b8ac5c04d445908b0b2399903bb461","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ee39da8708b440de8aeec8e443a625cf","IPY_MODEL_cbee9e60f88d4c65acff7e3d4b34cebb"]}},"80b8ac5c04d445908b0b2399903bb461":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ee39da8708b440de8aeec8e443a625cf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e0672f84471c432e97d3ee0a3778160b","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b6a8c684aa3b48ef8f9cca753425160b"}},"cbee9e60f88d4c65acff7e3d4b34cebb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2e0fb2872ab74a72a1303e3367e02541","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 182042624/? [00:26&lt;00:00, 21298058.04it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_47dfd8f131d447d78501bf6764aa4302"}},"e0672f84471c432e97d3ee0a3778160b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b6a8c684aa3b48ef8f9cca753425160b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2e0fb2872ab74a72a1303e3367e02541":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"47dfd8f131d447d78501bf6764aa4302":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d104590766044ec99b4f3204541f0341":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a311d9659c69406c9844808aa350cdec","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e097d751aeae4728b5e52e22609af0b2","IPY_MODEL_a390d0895f1f4f1f9f6e1fac8141ad5d"]}},"a311d9659c69406c9844808aa350cdec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e097d751aeae4728b5e52e22609af0b2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_90fce40fad49400ab68ddbc7a1fe4acb","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d0238c567d654efc82b4ae72e08311a0"}},"a390d0895f1f4f1f9f6e1fac8141ad5d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_978244e695d845ff871766cda896306a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 6586368/? [00:11&lt;00:00, 19349917.36it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_94817180afbf46009db7b2f1c652eb7d"}},"90fce40fad49400ab68ddbc7a1fe4acb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d0238c567d654efc82b4ae72e08311a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"978244e695d845ff871766cda896306a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"94817180afbf46009db7b2f1c652eb7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"deepnote_notebook_id":"d5ea81eb-6b23-4dca-8009-5003450a8b3d","deepnote_execution_queue":[{"cellId":"00043-bca59312-65f1-436f-b2cc-c40d3b456dc6","sessionId":"d6608d71-3acf-4c29-9acd-65bd0d527978","msgId":"08d66088-74ba-42a0-b11a-8a2704bb144b"}]}}