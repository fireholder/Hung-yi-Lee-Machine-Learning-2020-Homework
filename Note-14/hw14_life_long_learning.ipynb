{"cells":[{"cell_type":"markdown","source":"## LifeLong Machine Learning\n\n### 助教的投影片連結\n[投影片](https://docs.google.com/presentation/d/13JmcOZ9i_m5xJbRBKNMAKE1fIzGhyaeLck3frY0B2xY/edit?usp=sharing)\n\n### 定義\n老師的影片有詳細說明定義 這裡不細提 詳細可以參考 [lifelong learning](https://youtu.be/7qT5P9KJnWo) \n\n\n### 方法\n在2019年底，有人提出了一個大匯整將lifelong learning 的方法，從2016- 2019 年初 的模型做了歸類，大致上可以分成三種大方法\n* Replay-based methods\n* Regularization-based methods\n* Parameter isolation methods\n\n<img src=\"https://i.ibb.co/VDFJkWG/2019-12-29-17-25.png\" width=\"100%\">\n\n在這次的作業之中，我們要走過一次regularization-based methods 裡面的 prior-focused的兩種方法 分別是 EWC 和 MAS 這兩種方法\n\n圖片出處 [Continual Learning in Neural\nNetworks](https://arxiv.org/pdf/1910.02718.pdf)\n\n若有任何問題，歡迎來信至助教信箱 ntu-ml-2020spring-ta@googlegroups.com\n\n\n\n","metadata":{"id":"LD5roJkIvoRj","cell_id":"00000-30beeffd-434a-46ba-97c0-8335d8229c93"}},{"cell_type":"code","metadata":{"id":"ILD0GKIgJPHb","cell_id":"00001-aababcb6-b837-488d-bc05-61087c33b382","output_cleared":false,"source_hash":"31587f3","execution_start":1604580937538,"execution_millis":0},"source":"%%capture\n# !pip3 install torch torchvision","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Libraries","metadata":{"id":"On1VZz4HUIJw","cell_id":"00002-310b6c2b-c018-422c-a9f9-a80f01f61834"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00003-56bd60d6-261b-4d65-ab9a-04396d1507c5","output_cleared":false,"source_hash":"3b55d45b","execution_start":1604580954916,"execution_millis":42203},"source":"!pip install torch==1.7.0","execution_count":null,"outputs":[{"name":"stdout","text":"Collecting torch==1.7.0\n  Downloading torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7 MB)\n\u001b[K     |████████████████████████████████| 776.7 MB 3.1 kB/s \n\u001b[?25hCollecting typing-extensions\n  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\nCollecting dataclasses\n  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\nCollecting future\n  Downloading future-0.18.2.tar.gz (829 kB)\n\u001b[K     |████████████████████████████████| 829 kB 45.5 MB/s \n\u001b[?25hRequirement already satisfied: numpy in /opt/venv/lib/python3.7/site-packages (from torch==1.7.0) (1.19.2)\nBuilding wheels for collected packages: future\n  Building wheel for future (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491059 sha256=c2e468be1a1efbb129af9508e52ac60a039f0592aabb03cd87a13f65d6589444\n  Stored in directory: /home/jovyan/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\nSuccessfully built future\nInstalling collected packages: typing-extensions, dataclasses, future, torch\nSuccessfully installed dataclasses-0.6 future-0.18.2 torch-1.7.0 typing-extensions-3.7.4.3\n\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\nYou should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00004-48dd2b5e-77bf-489a-b7a4-16f96ec5b290","output_cleared":false,"source_hash":"92ae8c5a","execution_start":1604581027922,"execution_millis":2613},"source":"!pip install torchvision==0.8.1","execution_count":null,"outputs":[{"name":"stdout","text":"Collecting torchvision==0.8.1\n  Downloading torchvision-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (12.7 MB)\n\u001b[K     |████████████████████████████████| 12.7 MB 8.6 MB/s \n\u001b[?25hRequirement already satisfied: numpy in /opt/venv/lib/python3.7/site-packages (from torchvision==0.8.1) (1.19.2)\nRequirement already satisfied: pillow>=4.1.1 in /opt/venv/lib/python3.7/site-packages (from torchvision==0.8.1) (7.2.0)\nRequirement already satisfied: torch==1.7.0 in /opt/venv/lib/python3.7/site-packages (from torchvision==0.8.1) (1.7.0)\nRequirement already satisfied: typing-extensions in /opt/venv/lib/python3.7/site-packages (from torch==1.7.0->torchvision==0.8.1) (3.7.4.3)\nRequirement already satisfied: dataclasses in /opt/venv/lib/python3.7/site-packages (from torch==1.7.0->torchvision==0.8.1) (0.6)\nRequirement already satisfied: future in /opt/venv/lib/python3.7/site-packages (from torch==1.7.0->torchvision==0.8.1) (0.18.2)\nInstalling collected packages: torchvision\nSuccessfully installed torchvision-0.8.1\n\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\nYou should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"id":"dLnpJTNtje_J","cell_id":"00003-5bd7596f-aeab-44fa-8530-e726a2b9d886","output_cleared":false,"source_hash":"a02c94c0","execution_millis":455,"execution_start":1604645968009},"source":"%%capture\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torch.utils.data as data\nimport torch.utils.data.sampler as sampler\nimport torchvision\nfrom torchvision import datasets, transforms\n\nimport numpy as np\nimport os\nimport random\nfrom copy import deepcopy\nimport json\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# 模型","metadata":{"id":"KRGf4QAKFzz9","cell_id":"00004-465f5f91-a016-41c2-8187-c7089b94eda2"}},{"cell_type":"markdown","source":" >因為本次作業強調的是lifelong learning 的訓練方法，並非疊模型，所以今天我們所舉的例子，都會使用同一個模型來做訓練只是應用上不同lifelong learning的訓練方法， 在這次的作業的例子內 我們使用的是 一個 六層的 fully-connected layer 的 模型 加上 relu的 activation function.","metadata":{"id":"zZvlf0Wv7YdU","cell_id":"00005-c6e202c7-7f31-47c8-80d3-353818257108"}},{"cell_type":"markdown","source":"## Basic Model","metadata":{"id":"fkc3Z-4JYaPe","cell_id":"00006-572c4a0e-110c-4ca7-a6fc-aad17bfd60ad"}},{"cell_type":"code","metadata":{"id":"g8aQRs7ss3nx","cell_id":"00007-95ef991c-871e-4a98-b036-8e75e5be996d","output_cleared":false,"source_hash":"35150ce5","execution_millis":8,"execution_start":1604645984360},"source":"class Model(nn.Module):\n\n  def __init__(self):\n    super(Model, self).__init__()\n    self.fc1 = nn.Linear(3*32*32, 1024)\n    self.fc2 = nn.Linear(1024, 512)\n    self.fc3 = nn.Linear(512, 256)\n    self.fc4 = nn.Linear(256, 128)\n    self.fc5 = nn.Linear(128, 128)\n    self.fc6 = nn.Linear(128, 10)\n    self.relu = nn.ReLU()\n\n  def forward(self, x):\n    x = x.view(-1, 3*32*32)\n    x = self.fc1(x)\n    x = self.relu(x)\n    x = self.fc2(x)\n    x = self.relu(x)\n    x = self.fc3(x)\n    x = self.relu(x)\n    x = self.fc4(x)\n    x = self.relu(x)\n    x = self.fc5(x)\n    x = self.relu(x)\n    x = self.fc6(x)\n    return x\n","execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"以下我們將依序介紹這兩種方法 EWC 跟 MAS ","metadata":{"id":"AfeD8zfAccZe","cell_id":"00008-889174a4-bc75-46a5-942b-0a88f7786551"}},{"cell_type":"markdown","source":"## EWC","metadata":{"id":"qwri0rVpjd6h","cell_id":"00009-580d1e03-b8ee-405d-9951-670494ffd815"}},{"cell_type":"markdown","source":"### Elastic Weight Consolidation\n\n#### 概念\n老師在影片中已經把核心概念介紹給大家，那在這邊我想大家都非常了解了這個方法的概念，我們就直接進入主題\n\n今天我們的任務 是在學習連續的兩個 task task A 跟 task B:\n\n在 EWC 作法下 他的 loss function 會被定義如下\n $$\\mathcal{L}_B = \\mathcal{L}(\\theta) + \\sum_{i} \\frac{\\lambda}{2} F_i (\\theta_{i} - \\theta_{A,i}^{*})^2  $$\n\n先解釋這個 loss function 裡的變數，$\\mathcal{L}_B$ 是指 task B 的 loss, 會等於 正常的loss function $\\mathcal{L}(\\theta)$ (如果 是 classification 的問題,就是 cross entropy 的 loss function) 加上一個正則項 (regularization term) \n\n這個正則項的由兩個部份組成，第一個是 $F_i$ 也是這個方法的核心, 第二個部份是 $(\\theta_{i} - \\theta_{A,i}^{*})^2$  ,  $\\theta_{A,i}^{*}$ 代表的是 訓練完task A 存下來模型第 i 個參數的值, $\\theta_i$ 代表的是目前模型第i個參數的值，注意一點是模型的架構在這種 regularization based 的方法上，都是固定ㄉ，目前模型跟 task A 存下來的模型 架構都一樣只是值不一樣。底下我將說明這個 $F_i$ 是怎麼實做出來\n\n在老師的影片中，老師是以只有兩個參數的模型舉例子，那假設我今天模型就是一個 neural network(參數不只兩個) 該怎麼辦呢？   \n\n$F_i$ 對應到老師的影片敘述是指第i個參數的守衛，假設這個參數對 task A 很重要，那這個 $F_i$ 的值就會很大，這個參數盡量不能被更動...\n\n實際上這個參數的算法 即是 如下的式子\n\n$$ F = [ \\nabla \\log(p(y_n | x_n, \\theta_{A}^{*}) \\nabla \\log(p(y_n | x_n, \\theta_{A}^{*})^T ] $$ \n\n$F$ 之中 只以對角線的值去近似各個參數的 $F_i$ 值\n\n$p(y_n | x_n, \\theta_{A}^{*})$ 指的就是模型在給定之前 task 的 data $x_n$ 以及 給定 訓練完 task A 存下來的模型參數 $\\theta_A^*$ 得到 $y_n$($x_n$ 對應的 label ) 的 posterior probability.\n那統整一下作法就是 再對這個 $p(y_n | x_n, \\theta_{A}^{*})$ 取 log 再取 gradient 並且平方 ( parameter.grad )^2.\n\n每一個參數我都可以使用 pytorch 的 backward 之後再取 gradient 的性質算出各自的 $F_i$.\n\n有關這個 $F$ 其實博大精深，是來自於 fisher information matrix. 底下我放上有關這個lifelong learning 在 fisher information matrix 上是怎麼簡單的近似到這一項，簡單的推導來自 [Continual Learning in Neural\nNetworks](https://arxiv.org/pdf/1910.02718.pdf) 第2.4.1 小節 與 2.4 節\n\nFor You Information: [Elastic Weight Consolidation](https://arxiv.org/pdf/1612.00796.pdf)\n\n\n","metadata":{"id":"e3NePROJyWyW","cell_id":"00010-67ff8127-84a0-401d-a8b4-4908e8becee8"}},{"cell_type":"code","metadata":{"id":"K511GmRzyYWa","cell_id":"00011-836f19e1-6566-49cc-8fdd-e40a281d9342","output_cleared":false,"source_hash":"ddeae49e","execution_millis":3,"execution_start":1604645991862},"source":"\nclass EWC(object):\n  \"\"\"\n    @article{kirkpatrick2017overcoming,\n        title={Overcoming catastrophic forgetting in neural networks},\n        author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},\n        journal={Proceedings of the national academy of sciences},\n        year={2017},\n        url={https://arxiv.org/abs/1612.00796}\n    }\n  \"\"\"\n  def __init__(self, model: nn.Module, dataloaders: list, device):\n    \n    self.model = model\n    self.dataloaders = dataloaders\n    self.device = device\n    \n    self.params = {n: p for n, p in self.model.named_parameters() if p.requires_grad} #抓出模型的所有參數\n    self._means = {} # 初始化 平均參數\n    self._precision_matrices = self._calculate_importance() # 產生 EWC 的 Fisher (F) 矩陣 \n    \n    for n, p in self.params.items():\n      self._means[n] = p.clone().detach() # 算出每個參數的平均 （用之前任務的資料去算平均）\n  \n  def _calculate_importance(self):\n    precision_matrices = {}\n    for n, p in self.params.items(): # 初始化 Fisher (F) 的矩陣（都補零）\n      precision_matrices[n] = p.clone().detach().fill_(0)\n\n    self.model.eval()\n    dataloader_num=len(self.dataloaders)\n    number_data = sum([len(loader) for loader in self.dataloaders])\n    for dataloader in self.dataloaders:\n      for data in dataloader:\n        self.model.zero_grad()\n        input = data[0].to(self.device)\n        output = self.model(input).view(1, -1)\n        label = output.max(1)[1].view(-1)\n        \n        ############################################################################\n        #####                      產生 EWC 的 Fisher(F) 矩陣                    #####\n        ############################################################################    \n        loss = F.nll_loss(F.log_softmax(output, dim=1), label)             \n        loss.backward()                                                    \n                                                                           \n        for n, p in self.model.named_parameters():                         \n            precision_matrices[n].data += p.grad.data ** 2 / number_data   \n                                                                   \n    precision_matrices = {n: p for n, p in precision_matrices.items()}\n    return precision_matrices\n\n  def penalty(self, model: nn.Module):\n    loss = 0\n    for n, p in model.named_parameters():\n      _loss = self._precision_matrices[n] * (p - self._means[n]) ** 2\n      loss += _loss.sum()\n    return loss\n","execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## MAS","metadata":{"id":"jmsPw6avjl5B","cell_id":"00012-d0eed295-f7e3-4477-ba43-2979c2af8c53"}},{"cell_type":"markdown","source":"### Memory Aware Synapses\n概念:\n老師的影片中，將它歸類到和 EWC 一樣的方法，只是算這個 important weight 的方式不太一樣.底下我將說明這個方法該怎麼實做\n\nMAS:\n在 MAS 內，學習一個連續的 tasks, task A, 和 task B, 他的 loss function 定義如下:\n\n$$\\mathcal{L}_B = \\mathcal{L}(\\theta) + \\sum_{i} \\frac{\\lambda}{2} \\Omega_i (\\theta_{i} - \\theta_{A,i}^{*})^2$$\n\n和 ewc不同的是 式子中的 $F_i$ 被取代成 $\\Omega_i$ , $\\Omega_i$ 來自於以下的式子：\n\n$$\\Omega_i = || \\frac{\\partial \\ell_2^2(M(x_k; \\theta))}{\\partial \\theta_i} || $$ \n\n$x_k$ 是 來自於 前面 task 的 sample data。 式子上的作法就是對最後模型的 output vector (最後一層)做 l2 norm 後取平方 再對各自的weight微分(取gradient) 並且取 該 gradient 的絕對值，在該paper 中其實也可以對各個層的 output vector 做 l2 norm ( local 版本)，這邊只實做 global 的版本。\n\n\nFor Your Information: \n[Memory Aware Synapses](https://arxiv.org/pdf/1711.09601.pdf)\n \n\n\n\n\n","metadata":{"id":"C7fSYpALrAVw","cell_id":"00013-a3761ef1-31a8-40d5-a105-8f11a93e1aa7"}},{"cell_type":"code","metadata":{"id":"btFvFJMmqxE0","cell_id":"00014-45a8190e-c334-471f-93a9-440836ae8204","output_cleared":false,"source_hash":"fb6ee11f","execution_millis":0,"execution_start":1604645997846},"source":"\nclass MAS(object):\n    \"\"\"\n    @article{aljundi2017memory,\n      title={Memory Aware Synapses: Learning what (not) to forget},\n      author={Aljundi, Rahaf and Babiloni, Francesca and Elhoseiny, Mohamed and Rohrbach, Marcus and Tuytelaars, Tinne},\n      booktitle={ECCV},\n      year={2018},\n      url={https://eccv2018.org/openaccess/content_ECCV_2018/papers/Rahaf_Aljundi_Memory_Aware_Synapses_ECCV_2018_paper.pdf}\n    }\n    \"\"\"\n    def __init__(self, model: nn.Module, dataloaders: list, device):\n        self.model = model \n        self.dataloaders = dataloaders\n        self.params = {n: p for n, p in self.model.named_parameters() if p.requires_grad} #抓出模型的所有參數\n        self._means = {} # 初始化 平均參數\n        self.device = device\n        self._precision_matrices = self.calculate_importance() # 產生 MAS 的 Omega(Ω) 矩陣\n    \n        for n, p in self.params.items():\n            self._means[n] = p.clone().detach()\n    \n    def calculate_importance(self):\n        print('Computing MAS')\n\n        precision_matrices = {}\n        for n, p in self.params.items():\n            precision_matrices[n] = p.clone().detach().fill_(0) # 初始化 Omega(Ω) 矩陣（都補零）\n\n        self.model.eval()\n        dataloader_num = len(self.dataloaders)\n        num_data = sum([len(loader) for loader in self.dataloaders])\n        for dataloader in self.dataloaders:\n            for data in dataloader:\n                self.model.zero_grad()\n                output = self.model(data[0].to(self.device))\n\n                #######################################################################################\n                #####  產生 MAS 的 Omega(Ω) 矩陣 ( 對 output 向量 算他的 l2 norm 的平方) 再取 gradient  ####\n                #######################################################################################\n                output.pow_(2)                                                   \n                loss = torch.sum(output,dim=1)                                   \n                loss = loss.mean()                                               \n                loss.backward()                                                  \n                                          \n                for n, p in self.model.named_parameters():                      \n                    precision_matrices[n].data += p.grad.abs() / num_data ## difference with EWC      \n\n        precision_matrices = {n: p for n, p in precision_matrices.items()}\n        return precision_matrices\n\n    def penalty(self, model: nn.Module):\n        loss = 0\n        for n, p in model.named_parameters():\n            _loss = self._precision_matrices[n] * (p - self._means[n]) ** 2\n            loss += _loss.sum()\n        return loss","execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# 資料","metadata":{"id":"NWQ_JBlbFnKV","cell_id":"00015-120eccab-4cf6-4d92-87b2-019ee7bc2f0b"}},{"cell_type":"markdown","source":"## 資料預處理\n- 轉換 MNIST  ($1*28*28$) 到 ($3*32*32$)\n- 轉換 USPS   ($1*16*16$) 到 ($3*32*32$)\n- 正規化 圖片","metadata":{"id":"vdep_aMvUYqI","cell_id":"00016-ed9d7a76-27c4-445a-bd0d-147410b6278f"}},{"cell_type":"code","metadata":{"id":"xVHrWsHfIPtY","cell_id":"00017-92005e35-f293-4759-a622-6db8b27b1450","output_cleared":false,"source_hash":"bddcff31","execution_millis":0,"execution_start":1604646000682},"source":"class Convert2RGB(object):\n  \n  def __init__(self, num_channel):\n    self.num_channel = num_channel\n\n  def __call__(self, img):                                                                                                                                                                                                                              \n    # If the channel of img is not equal to desired size,\n    # then expand the channel of img to desired size.\n    img_channel = img.size()[0]\n    img = torch.cat([img] * (self.num_channel - img_channel + 1), 0)\n    return img\n\n\nclass Pad(object):\n\n  def __init__(self, size, fill=0, padding_mode='constant'):\n    self.size = size\n    self.fill = fill\n    self.padding_mode = padding_mode\n    \n  def __call__(self, img):\n    # If the H and W of img is not equal to desired size,\n    # then pad the channel of img to desired size.\n    img_size = img.size()[1]\n    assert ((self.size - img_size) % 2 == 0)\n    padding = (self.size - img_size) // 2\n    padding = (padding, padding, padding, padding)\n    return F.pad(img, padding, self.padding_mode, self.fill)\n\ndef get_transform():\n  transform = transforms.Compose([transforms.ToTensor(),\n                                  Pad(32),\n                                  Convert2RGB(3),\n                                  transforms.Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5])])\n  return transform\n","execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## 準備 資料集\n- MNIST   : 一張圖片資料大小:  $28*28*1$, 灰階 , 10 個種類\n- SVHN    : 一張圖片資料大小:  $32*32*3$, RGB , 10 個種類\n- USPS    : 一張圖片資料大小:  $16*16*1$, 灰階 , 10 個種類","metadata":{"id":"PW4r9Jd-etyG","cell_id":"00018-9c3436c6-e49e-46e1-9e44-790ab7500b12"}},{"cell_type":"code","metadata":{"id":"HPIeRDtIox0M","cell_id":"00019-fbac028f-1129-4d12-8e5d-ec63fd533c72","output_cleared":false,"source_hash":"ec6a75f","execution_millis":11,"execution_start":1604646003121},"source":"class Data():\n\n  def __init__(self, path):\n\n    transform = get_transform()\n\n    self.MNIST_dataset = datasets.MNIST(root = os.path.join(path, \"MNIST\"),\n                                        transform=transform,\n                                        train = True,\n                                        download = True)\n\n    self.SVHN_dataset = datasets.SVHN(root = os.path.join(path, \"SVHN\"),\n                                      transform=transform,\n                                      split='train',\n                                      download = True)\n\n    self.USPS_dataset = datasets.USPS(root = os.path.join(path, \"USPS\"),\n                                            transform=transform,\n                                            train = True,\n                                            download = True)\n    \n  def get_datasets(self):\n      a = [(self.SVHN_dataset, \"SVHN\"),(self.MNIST_dataset, \"MNIST\"),(self.USPS_dataset, \"USPS\")]\n      return a\n","execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## 建立 Dataloader\n- *.train_loader: 拿取訓練集並訓練 \\\\\n- *.val_loader: 拿取驗證集並驗測結果 \\\\","metadata":{"id":"eMtV82EPjsld","cell_id":"00020-4575b865-eabb-4ad3-af92-edb58af8831b"}},{"cell_type":"code","metadata":{"id":"29-5g8ZHjs_3","cell_id":"00021-f612b082-d589-44c5-a614-c76c02aed61f","output_cleared":false,"source_hash":"d4041783","execution_millis":3,"execution_start":1604646008597},"source":"class Dataloader():\n\n  def __init__(self, dataset, batch_size, split_ratio=0.1):\n    self.dataset = dataset[0]\n    self.name = dataset[1]\n    train_sampler, val_sampler = self.split_dataset(split_ratio)\n\n    self.train_dataset_size = len(train_sampler)\n    self.val_dataset_size = len(val_sampler)\n\n    self.train_loader = data.DataLoader(self.dataset, batch_size = batch_size, sampler=train_sampler)\n    self.val_loader = data.DataLoader(self.dataset, batch_size = batch_size, sampler=val_sampler)\n    self.train_iter = self.infinite_iter()\n\n  def split_dataset(self, split_ratio):\n    data_size = len(self.dataset)\n    split = int(data_size * split_ratio)\n    indices = list(range(data_size))\n    np.random.shuffle(indices)\n    train_idx, valid_idx = indices[split:], indices[:split]\n\n    train_sampler = sampler.SubsetRandomSampler(train_idx)\n    val_sampler = sampler.SubsetRandomSampler(valid_idx)\n    return train_sampler, val_sampler\n    \n  def infinite_iter(self):\n    it = iter(self.train_loader)\n    while True:\n      try:\n        ret = next(it)\n        yield ret\n      except StopIteration:\n        it = iter(self.train_loader)\n","execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# 小工具","metadata":{"id":"vzG5BWtHGA3p","cell_id":"00022-33e37c13-e17e-4d09-9262-f6ff2af99589"}},{"cell_type":"markdown","source":"## 儲存模型","metadata":{"id":"vMBoCSH5MBLN","cell_id":"00023-393db76d-acf5-4877-a6aa-891ef89c2506"}},{"cell_type":"code","metadata":{"id":"uCZuQrWiMGmH","cell_id":"00024-040b0162-c68a-4bdb-897b-16693038cade","output_cleared":false,"source_hash":"ba48cd1","execution_millis":0,"execution_start":1604646011579},"source":"def save_model(model, optimizer, store_model_path):\n  # save model and optimizer\n  torch.save(model.state_dict(), f'{store_model_path}.ckpt')\n  torch.save(optimizer.state_dict(), f'{store_model_path}.opt')\n  return\n","execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## 載入模型\n","metadata":{"id":"Nde98xvAMxAd","cell_id":"00025-5ce52029-4555-4769-86e2-b709fd118818"}},{"cell_type":"code","metadata":{"id":"FGzZ2Yp2MxK-","cell_id":"00026-0cefa0ae-92dd-4e3d-a828-00e8d15bef6c","output_cleared":false,"source_hash":"d991dbdb","execution_millis":3,"execution_start":1604646020143},"source":"def load_model(model, optimizer, load_model_path):\n  # load model and optimizer\n  print(f'Load model from {load_model_path}')\n  model.load_state_dict(torch.load(f'{load_model_path}.ckpt'))\n  optimizer.load_state_dict(torch.load(f'{load_model_path}.opt'))\n  return model, optimizer\n","execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## 建立模型 & 優化器","metadata":{"id":"eoz6awEcOIAz","cell_id":"00027-46f7b1f9-88d7-4ba2-9991-fd7b44b75774"}},{"cell_type":"code","metadata":{"id":"TvWqv_JlOOix","cell_id":"00028-5ef30e21-cf26-4417-8139-f5b0fa273134","output_cleared":false,"source_hash":"1ef255c","execution_millis":1,"execution_start":1604646028193},"source":"def build_model(data_path, batch_size, learning_rate): \n  # create model\n  model = Model().to(device)\n  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n  data = Data(data_path)\n  datasets = data.get_datasets()\n  tasks = []\n  for dataset in datasets:\n    tasks.append(Dataloader(dataset, batch_size))\n\n  return model, optimizer, tasks\n","execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# 訓練","metadata":{"id":"74De0sS-O50R","cell_id":"00029-03956a04-5d1c-412c-b67c-8e7ce36f6d23"}},{"cell_type":"markdown","source":"## 正常訓練 ( baseline )","metadata":{"id":"_q9Co3vuGWfu","cell_id":"00030-24af5e68-621c-418d-bffb-d1b1730f8c3f"}},{"cell_type":"code","metadata":{"id":"TBnE9GbiO8Ob","cell_id":"00031-bd638970-1789-4169-ae6e-620bb7bbd4ba","output_cleared":false,"source_hash":"8be357b7","execution_millis":11,"execution_start":1604646032433},"source":"def normal_train(model, optimizer, task, total_epochs, summary_epochs):\n  model.train()\n  model.zero_grad()\n  ceriation = nn.CrossEntropyLoss()\n  losses = []\n  loss = 0.0\n  for epoch in range(summary_epochs):\n    imgs, labels = next(task.train_iter)\n    imgs, labels = imgs.to(device), labels.to(device)\n    outputs = model(imgs)\n    ce_loss = ceriation(outputs, labels)\n    \n    optimizer.zero_grad()\n    ce_loss.backward()\n    optimizer.step()\n\n    loss += ce_loss.item()\n    if (epoch + 1) % 50 == 0:\n      loss = loss / 50\n      print (\"\\r\", \"train task {} [{}] loss: {:.3f}      \".format(task.name, (total_epochs + epoch + 1), loss), end=\" \")\n      losses.append(loss)\n      loss = 0.0\n    \n  return model, optimizer, losses\n  ","execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## EWC 訓練","metadata":{"id":"m2FlojHR_4qb","cell_id":"00032-e2f54e0c-6734-429a-af9e-d1e9389b369c"}},{"cell_type":"code","metadata":{"id":"nLHALesw_61i","cell_id":"00033-e7259efb-3f1a-459e-ad52-41e9909fbaa1","output_cleared":false,"source_hash":"af979218","execution_millis":3,"execution_start":1604646035779},"source":"def ewc_train(model, optimizer, task, total_epochs, summary_epochs, ewc, lambda_ewc):\n  model.train()\n  model.zero_grad()\n  ceriation = nn.CrossEntropyLoss()\n  losses = []\n  loss = 0.0\n  for epoch in range(summary_epochs):\n    imgs, labels = next(task.train_iter)\n    imgs, labels = imgs.to(device), labels.to(device)\n    outputs = model(imgs)\n    ce_loss = ceriation(outputs, labels)\n    total_loss = ce_loss\n    ewc_loss = ewc.penalty(model)\n    total_loss += lambda_ewc * ewc_loss \n    \n    optimizer.zero_grad()\n    total_loss.backward()\n    optimizer.step()\n\n    loss += total_loss.item()\n    if (epoch + 1) % 50 == 0:\n      loss = loss / 50\n      print (\"\\r\", \"train task {} [{}] loss: {:.3f}      \".format(task.name, (total_epochs + epoch + 1), loss), end=\" \")\n      losses.append(loss)\n      loss = 0.0\n    \n  return model, optimizer, losses","execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## MAS 訓練","metadata":{"id":"0B6to7GuqvPX","cell_id":"00034-119bb58a-55ee-4179-8c3f-7a9c50e23389"}},{"cell_type":"code","metadata":{"id":"fWhZz9uZquew","cell_id":"00035-2671919c-702b-4c3d-9375-e7e16402edd8","output_cleared":false,"source_hash":"d596fbfc","execution_millis":3,"execution_start":1604646039212},"source":"def mas_train(model, optimizer, task, total_epochs, summary_epochs, mas_tasks, lambda_mas,alpha=0.8):\n  model.train()\n  model.zero_grad()\n  ceriation = nn.CrossEntropyLoss()\n  losses = []\n  loss = 0.0\n  for epoch in range(summary_epochs):\n    imgs, labels = next(task.train_iter)\n    imgs, labels = imgs.to(device), labels.to(device)\n    outputs = model(imgs)\n    ce_loss = ceriation(outputs, labels)\n    total_loss = ce_loss\n    mas_tasks.reverse()\n    if len(mas_tasks) > 1:\n        preprevious = 1 - alpha\n        scalars = [alpha,preprevious]\n        for mas,scalar in zip(mas_tasks[:2],scalars):\n            mas_loss = mas.penalty(model)\n            total_loss += lambda_mas * mas_loss * scalar\n    elif len(mas_tasks) == 1:\n        mas_loss = mas_tasks[0].penalty(model)\n        total_loss += lambda_mas * mas_loss\n    else:\n        pass\n    \n    optimizer.zero_grad()\n    total_loss.backward()\n    optimizer.step()\n\n    loss += total_loss.item()\n    if (epoch + 1) % 50 == 0:\n      loss = loss / 50\n      print (\"\\r\", \"train task {} [{}] loss: {:.3f}      \".format(task.name, (total_epochs + epoch + 1), loss), end=\" \")\n      losses.append(loss)\n      loss = 0.0\n    \n  return model, optimizer, losses","execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## 驗證\n","metadata":{"id":"6cuHVXxAfHrA","cell_id":"00036-8b11447d-c5d3-492b-8ee2-76cf43912c8b"}},{"cell_type":"code","metadata":{"id":"ZBp-n3FrfOCe","cell_id":"00037-7ce5beee-3f6a-4cfd-8cd3-5d7b69c0a0c4","output_cleared":false,"source_hash":"38c66102","execution_millis":0,"execution_start":1604646042486},"source":"def val(model, task):\n  model.eval()\n  correct_cnt = 0\n  for imgs, labels in task.val_loader:\n    imgs, labels = imgs.to(device), labels.to(device)\n    outputs = model(imgs)\n    _, pred_label = torch.max(outputs.data, 1)\n\n    correct_cnt += (pred_label == labels.data).sum().item()\n    \n  return correct_cnt / task.val_dataset_size\n","execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## 主訓練程序\n","metadata":{"id":"dFEYmPAlx_SX","cell_id":"00038-95a1c928-f0ce-4cb3-af7a-d69fc3243169"}},{"cell_type":"code","metadata":{"id":"cJ54vDP2yC2S","cell_id":"00039-30271b4f-51b4-4803-97a5-99a06c5ef310","output_cleared":false,"source_hash":"a5ec39","execution_millis":3,"execution_start":1604646045294},"source":"def train_process(model, optimizer, tasks, config):\n  task_loss, acc = {}, {}\n  for task_id, task in enumerate(tasks):\n    print ('\\n')\n    total_epochs = 0\n    task_loss[task.name] = []\n    acc[task.name] = []\n    if config.mode == 'basic' or task_id == 0:\n      while (total_epochs < config.num_epochs):\n        model, optimizer, losses = normal_train(model, optimizer, task, total_epochs, config.summary_epochs)\n        task_loss[task.name] +=  losses\n\n        for subtask in range(task_id + 1):\n          acc[tasks[subtask].name].append(val(model, tasks[subtask]))\n\n        total_epochs += config.summary_epochs\n        if total_epochs % config.store_epochs == 0 or total_epochs >= config.num_epochs:\n          save_model(model, optimizer, config.store_model_path)\n    \n    if config.mode == 'ewc' and task_id > 0:\n      old_dataloaders = []\n      for old_task in range(task_id): \n        old_dataloaders += [tasks[old_task].val_loader]\n      ewc = EWC(model, old_dataloaders, device)\n      while (total_epochs < config.num_epochs):\n        model, optimizer, losses = ewc_train(model, optimizer, task, total_epochs, config.summary_epochs, ewc, config.lifelong_coeff)\n        task_loss[task.name] +=  losses\n\n        for subtask in range(task_id + 1):\n          acc[tasks[subtask].name].append(val(model, tasks[subtask]))\n\n        total_epochs += config.summary_epochs\n        if total_epochs % config.store_epochs == 0 or total_epochs >= config.num_epochs:\n          save_model(model, optimizer, config.store_model_path)\n\n    if config.mode == 'mas' and task_id > 0:\n      old_dataloaders = []\n      mas_tasks = []\n      for old_task in range(task_id): \n        old_dataloaders += [tasks[old_task].val_loader]\n        mas = MAS(model, old_dataloaders, device)\n        mas_tasks += [mas]\n      while (total_epochs < config.num_epochs):\n        model, optimizer, losses = mas_train(model, optimizer, task, total_epochs, config.summary_epochs, mas_tasks, config.lifelong_coeff)\n        task_loss[task.name] +=  losses\n\n        for subtask in range(task_id + 1):\n          acc[tasks[subtask].name].append(val(model, tasks[subtask]))\n\n        total_epochs += config.summary_epochs\n        if total_epochs % config.store_epochs == 0 or total_epochs >= config.num_epochs:\n          save_model(model, optimizer, config.store_model_path)\n\n    if config.mode == 'scp' and task_id > 0:\n      pass\n      ########################################\n      ##       TODO 區塊 （ PART 2 ）         ##\n      ########################################\n      ##    PART 2  implementation 的部份    ##\n      ##   你也可以寫別的 regularization 方法  ##\n      ##    助教這裡有提供的是  scp    的 作法   ##\n      ##     Slicer Cramer Preservation     ##\n      ########################################\n      ########################################\n      ##       TODO 區塊 （ PART 2 ）         ##\n      ########################################\n  return task_loss, acc\n","execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# 設定","metadata":{"id":"7PbfgB3n9eoT","cell_id":"00040-5a72a63c-a9eb-4e8e-a470-5ad25ca83acc"}},{"cell_type":"code","metadata":{"id":"3kWSZ4w39gzj","cell_id":"00041-5bcc16f2-f36a-4188-9d26-cf53ae95d5af","output_cleared":false,"source_hash":"1912f51f","execution_millis":5,"execution_start":1604646051464},"source":" class configurations(object):\n  def __init__(self):\n    self.batch_size = 256\n    self.num_epochs = 10000\n    self.store_epochs = 250\n    self.summary_epochs = 250\n    self.learning_rate = 0.0005\n    self.load_model = False\n    self.store_model_path = \"./model\"\n    self.load_model_path = \"./model\"\n    self.data_path = \"./data\"\n    self.mode = None\n    self.lifelong_coeff = 0.5\n\n###### 你也可以自己設定參數   ########\n###### 但上面的參數 是這次作業的預設直 #########\n","execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"#主程式區塊\n- 給 EWC, MAS 超參數 $\\lambda$ \n- 訓練","metadata":{"id":"w464f4KOLUh6","cell_id":"00042-75b0bf89-680f-4ab1-a42c-cc3fa119e223"}},{"cell_type":"code","metadata":{"id":"AJwVkorvLaSh","outputId":"d13d513a-fa13-45ae-b198-93e268c26844","colab":{"base_uri":"https://localhost:8080/","height":620,"referenced_widgets":["5dbf0aad2f184ed28d62aa04a3917234","e2299cb5c0434fa4b395616d44132f46","2548b480d28140269d7adedbafd37b00","2fa26176e4f04676a16d96c34590b80b","3d8a611f75984668849c47d8da55c774","1844220894384aaba01101c5dcb19557","e36fb5d801924c998d9b9daae1fea23f","72720e80c66f440ea75beac862cf94dc","57c35378a81f420da7c84d9067acefbb","a7d54badc91f4d8b91e7b2d7d0a05417","d09ecbd109a5431baa472da46739dc8f","f04e98e5a2e14712aa7fe11894cfde20","20101d312f1a423da807b3e2000a425b","ab1480fe2bdd41f0aa31cbb7e3da4846","31013f55b5ec459697fcd5052583dcfd","104e0c9743d44f01b15b2fe0c5d8ef6c","ef63806fa39b43b18b5422581d491ca9","f2f9463db89d41f193a36b148edeedf9","e7c44691fc2a49dcaa92c0778053e726","1d518c4702a54c4cbf732744cb9d2cdf","631d9df8d22d45d2b6ec4ac50e996498","f14b0c6c6d1246269d5854c9b8d0d08d","36a70cefd0bb4dbf8f4c79d6ba4b24f5","d2a80e1f21c34f32bbdbc16f5dde67ef","f3522a02d6944613a65075a68381aa86","334b6c92e01842b4a7fe6dfc9153ff7f","ff04a5d339754fd29a309b278385e9dd","75947f9968b54fefb703584af8c9a3c1","ce329a663ab84dafbb427c6b277492f3","d5b0ae3de4264eb4829664ef4bc66c8f","debfda6eb9434892a08f976220fdfc0f","69912206ffa54a56b611313cc634ee6f","8deb94ae3b444b23b580d7d5195d7241","80b8ac5c04d445908b0b2399903bb461","ee39da8708b440de8aeec8e443a625cf","cbee9e60f88d4c65acff7e3d4b34cebb","e0672f84471c432e97d3ee0a3778160b","b6a8c684aa3b48ef8f9cca753425160b","2e0fb2872ab74a72a1303e3367e02541","47dfd8f131d447d78501bf6764aa4302","d104590766044ec99b4f3204541f0341","a311d9659c69406c9844808aa350cdec","e097d751aeae4728b5e52e22609af0b2","a390d0895f1f4f1f9f6e1fac8141ad5d","90fce40fad49400ab68ddbc7a1fe4acb","d0238c567d654efc82b4ae72e08311a0","978244e695d845ff871766cda896306a","94817180afbf46009db7b2f1c652eb7d"]},"cell_id":"00043-bca59312-65f1-436f-b2cc-c40d3b456dc6","output_cleared":false,"source_hash":"10d7393","execution_start":1604646078855,"execution_millis":18290985},"source":"\"\"\"\nthe order is svhn -> mnist -> usps\n===============================================\n\n\"\"\"\n# import tqdm\n\nif __name__ == '__main__':\n    mode_list = ['mas','ewc','basic']\n\n    ## hint: 謹慎的去選擇 lambda 超參數 / ewc: 80~400, mas: 0.1 - 10\n    ############################################################################\n    #####                           TODO 區塊 （ PART 1 ）                   #####\n    ############################################################################ \n    coeff_list = [0, 0 ,0 ]  ## 你需要在這 微調 lambda 參數, mas, ewc, baseline=0##  \n    ############################################################################\n    #####                           TODO 區塊 （ PART 1 ）                   #####\n    ############################################################################ \n    \n    config = configurations()\n    count = 0\n    for mode in mode_list:\n        config.mode = mode\n        config.lifelong_coeff = coeff_list[count]\n        print(\"{} training\".format(config.mode))    \n        model, optimizer, tasks = build_model(config.data_path, config.batch_size, config.learning_rate)\n        print (\"Finish build model\")\n        if config.load_model:\n            model, optimizer = load_model(model, optimizer, config.load_model_path)\n        task_loss, acc = train_process(model, optimizer, tasks, config)\n        with open(f'./{config.mode}_acc.txt', 'w') as f:\n            json.dump(acc, f)\n        count += 1\n","execution_count":19,"outputs":[{"name":"stdout","text":"mas training\nUsing downloaded and verified file: ./data/SVHN/train_32x32.mat\nFinish build model\n\n\n train task SVHN [10000] loss: 0.095       \n\nComputing MAS\n train task MNIST [10000] loss: 0.003       \n\nComputing MAS\nComputing MAS\n train task USPS [10000] loss: 0.000       ewc training\nUsing downloaded and verified file: ./data/SVHN/train_32x32.mat\nFinish build model\n\n\n train task SVHN [10000] loss: 0.074       \n\n train task MNIST [3700] loss: 0.016       ","output_type":"stream"},{"name":"stdout","text":" train task MNIST [10000] loss: 0.008       \n\n train task USPS [10000] loss: 0.005       basic training\nUsing downloaded and verified file: ./data/SVHN/train_32x32.mat\nFinish build model\n\n\n train task SVHN [10000] loss: 0.091       \n\n train task MNIST [10000] loss: 0.014       \n\n train task USPS [10000] loss: 0.001       ","output_type":"stream"}]},{"cell_type":"markdown","source":"# 畫出 Result 圖片","metadata":{"id":"DSJX338dA2He","cell_id":"00044-1cb56532-57fa-45f6-86d1-324867a99fbe"}},{"cell_type":"code","metadata":{"id":"4X_RvV4my5Jl","cell_id":"00045-f72ace30-00c8-4742-b60b-9a48ceeb1e9b","output_cleared":false,"source_hash":"90a8b843","execution_millis":361,"execution_start":1604665796388},"source":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\n\ndef plot_result(mode_list, task1, task2, task3):\n  \n    #draw the lines\n    count = 0\n    for reg_name in mode_list:\n        label = reg_name\n        with open(f'./{reg_name}_acc.txt', 'r') as f:\n            acc = json.load(f)\n        if count == 0: \n            color= 'red'\n        elif count  == 1:\n            color= 'blue'\n        else:\n            color = 'purple'\n        ax1=plt.subplot(3, 1, 1)\n        plt.plot(range(len(acc[task1])),acc[task1],color,label=label)\n        ax1.set_ylabel(task1)\n        ax2=plt.subplot(3, 1, 2,sharex=ax1,sharey=ax1)\n        plt.plot(range(len(acc[task3]),len(acc[task1])),acc[task2],color,label=label)\n        ax2.set_ylabel(task2)\n        ax3=plt.subplot(3, 1, 3,sharex=ax1,sharey=ax1)\n        ax3.set_ylabel(task3)\n        plt.plot(range(len(acc[task2]),len(acc[task1])),acc[task3],color,label=label)\n        count += 1\n    plt.ylim((0.02,1.02))\n    plt.legend()\n    plt.show()\n    return \n\nmode_list = ['ewc','mas','basic']\nplot_result(mode_list,'SVHN','MNIST','USPS')","execution_count":26,"outputs":[{"name":"stderr","text":"/opt/venv/lib/python3.7/site-packages/ipykernel_launcher.py:19: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n/opt/venv/lib/python3.7/site-packages/ipykernel_launcher.py:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n/opt/venv/lib/python3.7/site-packages/ipykernel_launcher.py:25: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n","output_type":"stream"},{"data":{"text/plain":"<Figure size 432x288 with 3 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"},"output_type":"display_data"}]},{"cell_type":"code","source":"import pandas as pd\n\nfor reg_name in mode_list:\n    with open(f'./{reg_name}_acc.txt', 'r') as f:\n            acc = json.load(f)\n    test_acc = pd.DataFrame(acc['MNIST'])\n    \ntest_acc","metadata":{"tags":[],"cell_id":"00048-28324362-8209-44c8-aa87-543ad275dd80","output_cleared":false,"source_hash":"a21de7da","execution_millis":1,"execution_start":1604666292752},"outputs":[{"output_type":"execute_result","execution_count":34,"data":{"application/vnd.deepnote.dataframe.v2+json":{"row_count":80,"column_count":1,"columns":[{"name":0,"dtype":"float64","stats":{"unique_count":71,"nan_count":0,"min":0.827,"max":0.9826666666666667,"histogram":[{"bin_start":0.827,"bin_end":0.8425666666666667,"count":4},{"bin_start":0.8425666666666667,"bin_end":0.8581333333333333,"count":8},{"bin_start":0.8581333333333333,"bin_end":0.8736999999999999,"count":8},{"bin_start":0.8736999999999999,"bin_end":0.8892666666666666,"count":6},{"bin_start":0.8892666666666666,"bin_end":0.9048333333333334,"count":4},{"bin_start":0.9048333333333334,"bin_end":0.9204,"count":6},{"bin_start":0.9204,"bin_end":0.9359666666666666,"count":4},{"bin_start":0.9359666666666666,"bin_end":0.9515333333333333,"count":0},{"bin_start":0.9515333333333333,"bin_end":0.9671000000000001,"count":2},{"bin_start":0.9671000000000001,"bin_end":0.9826666666666667,"count":38}]}},{"name":"_deepnote_index_column","dtype":"int64"}],"rows_top":[{"0":0.9518333333333333,"_deepnote_index_column":0},{"0":0.9581666666666667,"_deepnote_index_column":1},{"0":0.9685,"_deepnote_index_column":2},{"0":0.9698333333333333,"_deepnote_index_column":3},{"0":0.9703333333333334,"_deepnote_index_column":4},{"0":0.9746666666666667,"_deepnote_index_column":5},{"0":0.9751666666666666,"_deepnote_index_column":6},{"0":0.9741666666666666,"_deepnote_index_column":7},{"0":0.9773333333333334,"_deepnote_index_column":8},{"0":0.9756666666666667,"_deepnote_index_column":9},{"0":0.975,"_deepnote_index_column":10},{"0":0.9768333333333333,"_deepnote_index_column":11},{"0":0.9783333333333334,"_deepnote_index_column":12},{"0":0.9758333333333333,"_deepnote_index_column":13},{"0":0.9728333333333333,"_deepnote_index_column":14},{"0":0.971,"_deepnote_index_column":15},{"0":0.9808333333333333,"_deepnote_index_column":16},{"0":0.9796666666666667,"_deepnote_index_column":17},{"0":0.9781666666666666,"_deepnote_index_column":18},{"0":0.9761666666666666,"_deepnote_index_column":19},{"0":0.975,"_deepnote_index_column":20},{"0":0.9766666666666667,"_deepnote_index_column":21},{"0":0.9773333333333334,"_deepnote_index_column":22},{"0":0.979,"_deepnote_index_column":23},{"0":0.9783333333333334,"_deepnote_index_column":24},{"0":0.9826666666666667,"_deepnote_index_column":25},{"0":0.98,"_deepnote_index_column":26},{"0":0.981,"_deepnote_index_column":27},{"0":0.9803333333333333,"_deepnote_index_column":28},{"0":0.975,"_deepnote_index_column":29},{"0":0.9786666666666667,"_deepnote_index_column":30},{"0":0.981,"_deepnote_index_column":31},{"0":0.977,"_deepnote_index_column":32},{"0":0.9721666666666666,"_deepnote_index_column":33},{"0":0.9806666666666667,"_deepnote_index_column":34},{"0":0.9781666666666666,"_deepnote_index_column":35},{"0":0.9808333333333333,"_deepnote_index_column":36},{"0":0.978,"_deepnote_index_column":37},{"0":0.9815,"_deepnote_index_column":38},{"0":0.9735,"_deepnote_index_column":39},{"0":0.918,"_deepnote_index_column":40},{"0":0.9226666666666666,"_deepnote_index_column":41},{"0":0.9085,"_deepnote_index_column":42},{"0":0.9326666666666666,"_deepnote_index_column":43},{"0":0.931,"_deepnote_index_column":44},{"0":0.9303333333333333,"_deepnote_index_column":45},{"0":0.9075,"_deepnote_index_column":46},{"0":0.907,"_deepnote_index_column":47},{"0":0.9053333333333333,"_deepnote_index_column":48},{"0":0.8828333333333334,"_deepnote_index_column":49},{"0":0.8853333333333333,"_deepnote_index_column":50},{"0":0.8831666666666667,"_deepnote_index_column":51},{"0":0.8876666666666667,"_deepnote_index_column":52},{"0":0.8915,"_deepnote_index_column":53},{"0":0.827,"_deepnote_index_column":54},{"0":0.8898333333333334,"_deepnote_index_column":55},{"0":0.8833333333333333,"_deepnote_index_column":56},{"0":0.9063333333333333,"_deepnote_index_column":57},{"0":0.898,"_deepnote_index_column":58},{"0":0.9005,"_deepnote_index_column":59},{"0":0.866,"_deepnote_index_column":60},{"0":0.8691666666666666,"_deepnote_index_column":61},{"0":0.8721666666666666,"_deepnote_index_column":62},{"0":0.8801666666666667,"_deepnote_index_column":63},{"0":0.8725,"_deepnote_index_column":64},{"0":0.841,"_deepnote_index_column":65},{"0":0.863,"_deepnote_index_column":66},{"0":0.864,"_deepnote_index_column":67},{"0":0.868,"_deepnote_index_column":68},{"0":0.864,"_deepnote_index_column":69},{"0":0.8393333333333334,"_deepnote_index_column":70},{"0":0.8546666666666667,"_deepnote_index_column":71},{"0":0.8568333333333333,"_deepnote_index_column":72},{"0":0.8468333333333333,"_deepnote_index_column":73},{"0":0.8473333333333334,"_deepnote_index_column":74},{"0":0.8516666666666667,"_deepnote_index_column":75},{"0":0.8546666666666667,"_deepnote_index_column":76},{"0":0.8418333333333333,"_deepnote_index_column":77},{"0":0.8471666666666666,"_deepnote_index_column":78},{"0":0.8465,"_deepnote_index_column":79}],"rows_bottom":null},"text/plain":"           0\n0   0.951833\n1   0.958167\n2   0.968500\n3   0.969833\n4   0.970333\n..       ...\n75  0.851667\n76  0.854667\n77  0.841833\n78  0.847167\n79  0.846500\n\n[80 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.951833</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.958167</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.968500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.969833</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.970333</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>0.851667</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>0.854667</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>0.841833</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>0.847167</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>0.846500</td>\n    </tr>\n  </tbody>\n</table>\n<p>80 rows × 1 columns</p>\n</div>"},"metadata":{}}],"execution_count":34},{"cell_type":"markdown","source":"在今年 ICLR 2020 的 paper，有以這兩種方法做 baseline，並對這兩種方法各自做了一個 geometry view，也提出新的方法，有興趣的人可以參考\n\npaper link 如下 [SLICED CRAMER´ SYNAPTIC CONSOLIDATION FOR\nPRESERVING DEEPLY LEARNED REPRESENTATIONS](https://openreview.net/pdf?id=BJge3TNKwH)","metadata":{"id":"43QGlXTxyzw_","cell_id":"00046-771f4886-afe1-4a1e-97c9-be45f2a87ca6"}},{"cell_type":"markdown","source":"# 進階 \n請實做其他的 regularization 的方法，助教有提供的是 SCP 的作法，\n\n你也可以考慮實做出 SI, Rimennian Walk, IMM, 或是上面的方法, \n\n你可以參考助教上方的寫法，寫出雷同的 class 跟 training 來 train，\n\n記得畫出與上方雷同的 evaluation 圖表 (show result) example 需要比對的話 可以參考助教給的 slide。\n","metadata":{"id":"cbMUPaN_zAs7","cell_id":"00047-aaccdb4c-4dbe-4ab0-962d-a4000c528bcd"}},{"cell_type":"code","metadata":{"id":"m3aOQ2XI-Prm","cell_id":"00048-089a31df-7b17-4ffb-a280-b80a02c4403b"},"source":"def sample_spherical(npoints, ndim=3):\n    vec = np.random.randn(ndim, npoints)\n    vec /= np.linalg.norm(vec, axis=0)\n    return vec","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bcjtln1T6U7T","cell_id":"00049-b553f117-49a9-45b7-985d-2a89e9897cc5"},"source":"class SCP(object):\n    \"\"\"\n    OPEN REVIEW VERSION:\n    https://openreview.net/forum?id=BJge3TNKwH\n    \"\"\"\n    def __init__(self, model: nn.Module, dataloaders: list, L: int, device):\n        self.model = model \n        self.dataloaders = dataloaders\n        self.params = {n: p for n, p in self.model.named_parameters() if p.requires_grad}\n        self._means = {}\n        self.L= L\n        self.device = device\n        self._precision_matrices = self.calculate_importance()\n    \n        for n, p in self.params.items():\n            self._means[n] = p.clone().detach()\n    \n    def calculate_importance(self):\n        print('Computing SCP')\n\n        precision_matrices = {}\n        for n, p in self.params.items():\n            precision_matrices[n] = p.clone().detach().fill_(0)\n\n        self.model.eval()\n        dataloader_num = len(self.dataloaders)\n        num_data = sum([len(loader) for loader in self.dataloaders])\n        for dataloader in self.dataloaders:\n            for data in dataloader:\n                self.model.zero_grad()\n                output = self.model(data[0].to(self.device))\n\n                ####################################################################################\n                #####                            TODO 區塊 （ PART 2 ）                           #####\n                ####################################################################################\n                ##### 產生 SCP 的 Gamma(Γ) 矩陣（ 如同 MAS 的 Omega(Ω) 矩陣, EWC 的 Fisher(F) 矩陣 ）#####\n                ####################################################################################\n                #####        1.對所有資料的 Output vector 取 平均 得到 平均 vector φ(:,θ_A* )       #####\n                ####################################################################################\n\n                ####################################################################################\n                #####   2. 隨機 從 單位球殼 取樣 L 個 vector ξ #（ Hint: sample_spherical() ）      #####\n                ####################################################################################\n\n                ####################################################################################\n                #####   3.    每一個 vector ξ 和 vector φ( :,θ_A* )內積得到 scalar ρ               #####\n                #####           對 scalar ρ 取 backward ， 每個參數得到各自的 gradient ∇ρ           #####\n                #####       每個參數的 gradient ∇ρ 取平方 取 L 平均 得到 各個參數的 Γ scalar          #####  \n                #####              所有參數的  Γ scalar 組合而成其實就是 Γ 矩陣                      #####\n                ####(hint: 記得 每次 backward 之後 要 zero_grad 去 清 gradient, 不然 gradient會累加 )######   \n                ####################################################################################\n      \n                ####################################################################################      \n                #####                            TODO 區塊 （ PART 2 ）                          #####\n                ####################################################################################\n\n        precision_matrices = {n: p for n, p in precision_matrices.items()}\n        return precision_matrices\n\n    def penalty(self, model: nn.Module):\n        loss = 0\n        for n, p in model.named_parameters():\n            _loss = self._precision_matrices[n] * (p - self._means[n]) ** 2\n            loss += _loss.sum()\n        return loss","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tp6EbyrhXoAH","cell_id":"00050-ddd768e0-c825-447f-8146-d98c4b887646"},"source":"def scp_train(model, optimizer, task, total_epochs, summary_epochs, scp_tasks, lambda_scp,alpha=0.65):\n  losses = []\n  loss = 0.0\n  ###############################\n  #####  TODO 區塊 （PART 2） #####\n  ###############################\n  ##  參考 MAS. EWC train 的寫法 ##                 \n  ###############################\n  #####  TODO 區塊 （PART 2） #####\n  ###############################\n  return model, optimizer, losses","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V1PxP2W3ZcrV","cell_id":"00051-f03cf635-81cc-410b-b329-e9ad3a62dfb6"},"source":"# if __name__ == \"__main__\": \n#   pass \n###############################\n#####  TODO 區塊 （PART 2） #####\n###############################\n##     參考 main 區塊一樣       ##                 \n##     的 code 結合新方法       ##\n###############################\n#####  TODO 區塊 （PART 2） #####\n###############################","execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc","metadata":{"tags":[],"cell_id":"00054-d750e1d7-5ae6-4213-9102-211ebadf86e3"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"acc","metadata":{"tags":[],"cell_id":"00055-a2c7e152-cb17-4e5e-be79-55f19273700d"},"outputs":[],"execution_count":null}],"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hw14_life_long_learning.ipynb","provenance":[],"collapsed_sections":["LD5roJkIvoRj"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"5dbf0aad2f184ed28d62aa04a3917234":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e2299cb5c0434fa4b395616d44132f46","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2548b480d28140269d7adedbafd37b00","IPY_MODEL_2fa26176e4f04676a16d96c34590b80b"]}},"e2299cb5c0434fa4b395616d44132f46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2548b480d28140269d7adedbafd37b00":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3d8a611f75984668849c47d8da55c774","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1844220894384aaba01101c5dcb19557"}},"2fa26176e4f04676a16d96c34590b80b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e36fb5d801924c998d9b9daae1fea23f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9920512/? [00:08&lt;00:00, 1157254.27it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_72720e80c66f440ea75beac862cf94dc"}},"3d8a611f75984668849c47d8da55c774":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1844220894384aaba01101c5dcb19557":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e36fb5d801924c998d9b9daae1fea23f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"72720e80c66f440ea75beac862cf94dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"57c35378a81f420da7c84d9067acefbb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a7d54badc91f4d8b91e7b2d7d0a05417","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d09ecbd109a5431baa472da46739dc8f","IPY_MODEL_f04e98e5a2e14712aa7fe11894cfde20"]}},"a7d54badc91f4d8b91e7b2d7d0a05417":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d09ecbd109a5431baa472da46739dc8f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_20101d312f1a423da807b3e2000a425b","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ab1480fe2bdd41f0aa31cbb7e3da4846"}},"f04e98e5a2e14712aa7fe11894cfde20":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_31013f55b5ec459697fcd5052583dcfd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 32768/? [00:11&lt;00:00, 79038.78it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_104e0c9743d44f01b15b2fe0c5d8ef6c"}},"20101d312f1a423da807b3e2000a425b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ab1480fe2bdd41f0aa31cbb7e3da4846":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"31013f55b5ec459697fcd5052583dcfd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"104e0c9743d44f01b15b2fe0c5d8ef6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ef63806fa39b43b18b5422581d491ca9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f2f9463db89d41f193a36b148edeedf9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e7c44691fc2a49dcaa92c0778053e726","IPY_MODEL_1d518c4702a54c4cbf732744cb9d2cdf"]}},"f2f9463db89d41f193a36b148edeedf9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e7c44691fc2a49dcaa92c0778053e726":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_631d9df8d22d45d2b6ec4ac50e996498","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f14b0c6c6d1246269d5854c9b8d0d08d"}},"1d518c4702a54c4cbf732744cb9d2cdf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_36a70cefd0bb4dbf8f4c79d6ba4b24f5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1654784/? [00:20&lt;00:00, 638394.45it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d2a80e1f21c34f32bbdbc16f5dde67ef"}},"631d9df8d22d45d2b6ec4ac50e996498":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f14b0c6c6d1246269d5854c9b8d0d08d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"36a70cefd0bb4dbf8f4c79d6ba4b24f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d2a80e1f21c34f32bbdbc16f5dde67ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f3522a02d6944613a65075a68381aa86":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_334b6c92e01842b4a7fe6dfc9153ff7f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ff04a5d339754fd29a309b278385e9dd","IPY_MODEL_75947f9968b54fefb703584af8c9a3c1"]}},"334b6c92e01842b4a7fe6dfc9153ff7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ff04a5d339754fd29a309b278385e9dd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ce329a663ab84dafbb427c6b277492f3","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d5b0ae3de4264eb4829664ef4bc66c8f"}},"75947f9968b54fefb703584af8c9a3c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_debfda6eb9434892a08f976220fdfc0f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 8192/? [00:00&lt;00:00, 13266.69it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_69912206ffa54a56b611313cc634ee6f"}},"ce329a663ab84dafbb427c6b277492f3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d5b0ae3de4264eb4829664ef4bc66c8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"debfda6eb9434892a08f976220fdfc0f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"69912206ffa54a56b611313cc634ee6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8deb94ae3b444b23b580d7d5195d7241":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_80b8ac5c04d445908b0b2399903bb461","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ee39da8708b440de8aeec8e443a625cf","IPY_MODEL_cbee9e60f88d4c65acff7e3d4b34cebb"]}},"80b8ac5c04d445908b0b2399903bb461":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ee39da8708b440de8aeec8e443a625cf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e0672f84471c432e97d3ee0a3778160b","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b6a8c684aa3b48ef8f9cca753425160b"}},"cbee9e60f88d4c65acff7e3d4b34cebb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2e0fb2872ab74a72a1303e3367e02541","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 182042624/? [00:26&lt;00:00, 21298058.04it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_47dfd8f131d447d78501bf6764aa4302"}},"e0672f84471c432e97d3ee0a3778160b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b6a8c684aa3b48ef8f9cca753425160b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2e0fb2872ab74a72a1303e3367e02541":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"47dfd8f131d447d78501bf6764aa4302":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d104590766044ec99b4f3204541f0341":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a311d9659c69406c9844808aa350cdec","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e097d751aeae4728b5e52e22609af0b2","IPY_MODEL_a390d0895f1f4f1f9f6e1fac8141ad5d"]}},"a311d9659c69406c9844808aa350cdec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e097d751aeae4728b5e52e22609af0b2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_90fce40fad49400ab68ddbc7a1fe4acb","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d0238c567d654efc82b4ae72e08311a0"}},"a390d0895f1f4f1f9f6e1fac8141ad5d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_978244e695d845ff871766cda896306a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 6586368/? [00:11&lt;00:00, 19349917.36it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_94817180afbf46009db7b2f1c652eb7d"}},"90fce40fad49400ab68ddbc7a1fe4acb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d0238c567d654efc82b4ae72e08311a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"978244e695d845ff871766cda896306a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"94817180afbf46009db7b2f1c652eb7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"deepnote_notebook_id":"d5ea81eb-6b23-4dca-8009-5003450a8b3d","deepnote_execution_queue":[]}}